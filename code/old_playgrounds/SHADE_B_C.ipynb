{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EAj-zvK2vyBveWHGIXVYSNeBNBOvPASh",
      "authorship_tag": "ABX9TyOJq1klZ6D6f1IVN1AeJBUZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eedduu/TFG/blob/main/code/old_playgorunds/SHADE_B_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP1ewpEQnsoF",
        "outputId": "6b84827b-d000-47cd-b83a-f95335c0b7e6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in ./anaconda3/lib/python3.7/site-packages (from ucimlrepo) (1.0.1)\n",
            "Collecting certifi>=2020.12.5\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/lib/python3.7/site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.7/site-packages (from pandas>=1.0.0->ucimlrepo) (2019.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in ./anaconda3/lib/python3.7/site-packages (from pandas>=1.0.0->ucimlrepo) (1.18.1)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=1.0.0->ucimlrepo) (1.14.0)\n",
            "Installing collected packages: certifi, ucimlrepo\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2019.11.28\n",
            "    Uninstalling certifi-2019.11.28:\n",
            "      Successfully uninstalled certifi-2019.11.28\n",
            "Successfully installed certifi-2024.7.4 ucimlrepo-0.0.7\n",
            "Requirement already satisfied: fastai in ./anaconda3/lib/python3.7/site-packages (2.7.12)\n",
            "Requirement already satisfied: scipy in ./anaconda3/lib/python3.7/site-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in ./anaconda3/lib/python3.7/site-packages (from fastai) (1.5.29)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in ./anaconda3/lib/python3.7/site-packages (from fastai) (0.14.1)\n",
            "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.7/site-packages (from fastai) (0.22.1)\n",
            "Requirement already satisfied: spacy<4 in ./anaconda3/lib/python3.7/site-packages (from fastai) (3.7.4)\n",
            "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.7/site-packages (from fastai) (3.1.3)\n",
            "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.7/site-packages (from fastai) (5.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in ./anaconda3/lib/python3.7/site-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: requests in ./anaconda3/lib/python3.7/site-packages (from fastai) (2.22.0)\n",
            "Requirement already satisfied: packaging in ./anaconda3/lib/python3.7/site-packages (from fastai) (20.1)\n",
            "Requirement already satisfied: pandas in ./anaconda3/lib/python3.7/site-packages (from fastai) (1.0.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in ./anaconda3/lib/python3.7/site-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in ./anaconda3/lib/python3.7/site-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pip in ./anaconda3/lib/python3.7/site-packages (from fastai) (20.0.2)\n",
            "Requirement already satisfied: torch<2.1,>=1.7 in ./anaconda3/lib/python3.7/site-packages (from fastai) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in ./anaconda3/lib/python3.7/site-packages (from scipy->fastai) (1.18.1)\n",
            "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.7/site-packages (from torchvision>=0.8.2->fastai) (4.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in ./anaconda3/lib/python3.7/site-packages (from scikit-learn->fastai) (0.14.1)\n",
            "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (45.2.0.post20200210)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (1.1.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (6.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (3.0.9)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (0.3.4)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (8.2.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (2.4.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (2.5.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (0.9.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (4.42.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.7/site-packages (from spacy<4->fastai) (2.11.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests->fastai) (1.25.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests->fastai) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests->fastai) (2024.7.4)\n",
            "Requirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from packaging->fastai) (1.14.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.7/site-packages (from pandas->fastai) (2019.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" in ./anaconda3/lib/python3.7/site-packages (from torch<2.1,>=1.7->fastai) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" in ./anaconda3/lib/python3.7/site-packages (from torch<2.1,>=1.7->fastai) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" in ./anaconda3/lib/python3.7/site-packages (from torch<2.1,>=1.7->fastai) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" in ./anaconda3/lib/python3.7/site-packages (from torch<2.1,>=1.7->fastai) (11.10.3.66)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./anaconda3/lib/python3.7/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai) (0.16.0)\n",
            "Requirement already satisfied: confection<0.2.0,>=0.0.4 in ./anaconda3/lib/python3.7/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai) (0.1.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./anaconda3/lib/python3.7/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
            "Requirement already satisfied: importlib-metadata; python_version == \"3.7\" in ./anaconda3/lib/python3.7/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (1.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./anaconda3/lib/python3.7/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in ./anaconda3/lib/python3.7/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.14.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./anaconda3/lib/python3.7/site-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in ./anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in ./anaconda3/lib/python3.7/site-packages (from jinja2->spacy<4->fastai) (1.1.1)\n",
            "Requirement already satisfied: wheel in ./anaconda3/lib/python3.7/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"->torch<2.1,>=1.7->fastai) (0.34.2)\n",
            "Requirement already satisfied: nbdev in ./anaconda3/lib/python3.7/site-packages (2.3.13)\n",
            "Requirement already satisfied: execnb>=0.1.4 in ./anaconda3/lib/python3.7/site-packages (from nbdev) (0.1.5)\n",
            "Requirement already satisfied: ghapi>=1.0.3 in ./anaconda3/lib/python3.7/site-packages (from nbdev) (1.0.4)\n",
            "Requirement already satisfied: asttokens in ./anaconda3/lib/python3.7/site-packages (from nbdev) (2.4.1)\n",
            "Requirement already satisfied: PyYAML in ./anaconda3/lib/python3.7/site-packages (from nbdev) (5.3)\n",
            "Requirement already satisfied: fastcore>=1.5.27 in ./anaconda3/lib/python3.7/site-packages (from nbdev) (1.5.29)\n",
            "Requirement already satisfied: astunparse in ./anaconda3/lib/python3.7/site-packages (from nbdev) (1.6.3)\n",
            "Requirement already satisfied: ipywidgets<=8.0.4 in ./anaconda3/lib/python3.7/site-packages (from nbdev) (7.5.1)\n",
            "Requirement already satisfied: watchdog in ./anaconda3/lib/python3.7/site-packages (from nbdev) (0.10.2)\n",
            "Requirement already satisfied: ipython in ./anaconda3/lib/python3.7/site-packages (from execnb>=0.1.4->nbdev) (7.12.0)\n",
            "Requirement already satisfied: pip in ./anaconda3/lib/python3.7/site-packages (from ghapi>=1.0.3->nbdev) (20.0.2)\n",
            "Requirement already satisfied: packaging in ./anaconda3/lib/python3.7/site-packages (from ghapi>=1.0.3->nbdev) (20.1)\n",
            "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.7/site-packages (from asttokens->nbdev) (1.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.7/site-packages (from astunparse->nbdev) (0.34.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in ./anaconda3/lib/python3.7/site-packages (from ipywidgets<=8.0.4->nbdev) (5.1.4)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in ./anaconda3/lib/python3.7/site-packages (from ipywidgets<=8.0.4->nbdev) (5.0.4)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in ./anaconda3/lib/python3.7/site-packages (from ipywidgets<=8.0.4->nbdev) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./anaconda3/lib/python3.7/site-packages (from ipywidgets<=8.0.4->nbdev) (3.5.1)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in ./anaconda3/lib/python3.7/site-packages (from watchdog->nbdev) (0.1.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.14.1)\n",
            "Requirement already satisfied: backcall in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.1.0)\n",
            "Requirement already satisfied: decorator in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (4.4.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (3.0.3)\n",
            "Requirement already satisfied: pygments in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (2.5.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in ./anaconda3/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (45.2.0.post20200210)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.7/site-packages (from packaging->ghapi>=1.0.3->nbdev) (2.4.6)\n",
            "Requirement already satisfied: tornado>=4.2 in ./anaconda3/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<=8.0.4->nbdev) (6.0.3)\n",
            "Requirement already satisfied: jupyter-client in ./anaconda3/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<=8.0.4->nbdev) (5.3.4)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./anaconda3/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (3.2.0)\n",
            "Requirement already satisfied: ipython-genutils in ./anaconda3/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in ./anaconda3/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (4.6.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in ./anaconda3/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (6.0.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->execnb>=0.1.4->nbdev) (0.6.0)\n",
            "Requirement already satisfied: parso>=0.5.0 in ./anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->execnb>=0.1.4->nbdev) (0.5.2)\n",
            "Requirement already satisfied: wcwidth in ./anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->execnb>=0.1.4->nbdev) (0.1.8)\n",
            "Requirement already satisfied: pyzmq>=13 in ./anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<=8.0.4->nbdev) (18.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<=8.0.4->nbdev) (2.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in ./anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (19.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (1.5.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in ./anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (0.15.7)\n",
            "Requirement already satisfied: terminado>=0.8.1 in ./anaconda3/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.8.3)\n",
            "Requirement already satisfied: Send2Trash in ./anaconda3/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in ./anaconda3/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (5.6.1)\n",
            "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (2.11.1)\n",
            "Requirement already satisfied: prometheus-client in ./anaconda3/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in ./anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<=8.0.4->nbdev) (2.2.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in ./anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in ./anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (1.4.2)\n",
            "Requirement already satisfied: bleach in ./anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (3.1.0)\n",
            "Requirement already satisfied: testpath in ./anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in ./anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in ./anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in ./anaconda3/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (1.1.1)\n",
            "Requirement already satisfied: webencodings in ./anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<=8.0.4->nbdev) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install fastai\n",
        "!pip install nbdev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from nbdev.showdoc import *\n",
        "from fastai.vision.all import *\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as FF\n",
        "import numpy\n",
        "import torchvision\n",
        "from torchvision import *\n",
        "import fastai\n",
        "import fastcore\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from fastai.tabular.all import TabularDataLoaders, TabularPandas, RandomSplitter, accuracy"
      ],
      "metadata": {
        "id": "wgsC5zc1n2I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "\n",
        "# metadata\n",
        "#print(breast_cancer_wisconsin_diagnostic.metadata)\n",
        "\n",
        "# variable information\n",
        "#print(breast_cancer_wisconsin_diagnostic.variables)\n",
        "\n",
        "\n",
        "df=pd.concat([X, y], axis=1)\n",
        "\n",
        "#X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "\n",
        "# Define the categorical and continuous variables\n",
        "cat_names = []\n",
        "#cont_names = [f'feature_{i}' for i in range(1, 31)]\n",
        "#cont_names = []\n",
        "#cont_names += ['texture1','perimeter1','area1','smoothness1','compactness1','concavity1','concave_points1','symmetry1','fractal_dimension1','texture2','perimeter2','area2','smoothness2','compactness2','concavity2','concave_points2','symmetry2','fractal_dimension2','texture3','perimeter3','area3','smoothness3','compactness3','concavity3','concave_points3','symmetry3','fractal_dimension3']\n",
        "cont_names = list(X.columns)\n",
        "dep_var = 'Diagnosis'\n",
        "\n",
        "splits=RandomSplitter(valid_pct = 0.3)(range_of(df))\n",
        "\n",
        "# Create TabularPandas\n",
        "to = TabularPandas(\n",
        "    df,\n",
        "    procs=[Categorify, FillMissing, Normalize],\n",
        "    #cat_names=cat_names,\n",
        "    cont_names=cont_names,\n",
        "    y_names=dep_var,\n",
        "    splits=splits\n",
        ")\n",
        "\n",
        "#INFORED: He hecho varias pruebas pero hay que tener en cuenta que el dataset es pequeño con lo que un tamaño grande es contraproducente\n",
        "dls = to.dataloaders(32)"
      ],
      "metadata": {
        "id": "q_EFtNs-n7M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#layers = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32, 32, 16, 16, 8]\n",
        "layers = [32]\n",
        "LEARN = tabular_learner(dls, layers=layers)"
      ],
      "metadata": {
        "id": "ExOEUEkdiUFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "CJWK7d_SAwY4",
        "outputId": "715d8584-33b0-4a84-e4cd-652dc1e71205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel (Input shape: 32 x 0)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     32 x 30             \n",
              "BatchNorm1d                               60         True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 1024           \n",
              "Linear                                    30720      True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               2048       True      \n",
              "Linear                                    1048576    True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               2048       True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 512            \n",
              "Linear                                    524288     True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               1024       True      \n",
              "Linear                                    262144     True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               1024       True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 256            \n",
              "Linear                                    131072     True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               512        True      \n",
              "Linear                                    65536      True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               512        True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 128            \n",
              "Linear                                    32768      True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               256        True      \n",
              "Linear                                    16384      True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               256        True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 64             \n",
              "Linear                                    8192       True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               128        True      \n",
              "Linear                                    4096       True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               128        True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 32             \n",
              "Linear                                    2048       True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               64         True      \n",
              "Linear                                    1024       True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               64         True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 16             \n",
              "Linear                                    512        True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               32         True      \n",
              "Linear                                    256        True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               32         True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 8              \n",
              "Linear                                    128        True      \n",
              "ReLU                                                           \n",
              "BatchNorm1d                               16         True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 2              \n",
              "Linear                                    18         True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 2,135,966\n",
              "Total trainable params: 2,135,966\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7803f2adae60>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/pyade-master')\n",
        "\n",
        "!pip install '/content/drive/MyDrive/pyade-master'\n",
        "\n",
        "import pyade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTNZuGXr-9GL",
        "outputId": "1cdbbdcc-3fe6-472b-b501-c588eae32712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/pyade-master\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyade-python\n",
            "  Building wheel for pyade-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyade-python: filename=pyade_python-1.0-py3-none-any.whl size=29040 sha256=f09c8eb2b3eb7943bc02703bc80e702953ae1db2136685b74fa0adba336980e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/b8/51/ff2ebef24405d3ef46ccb451f962b374b2745f263fb000c434\n",
            "Successfully built pyade-python\n",
            "Installing collected packages: pyade-python\n",
            "  Attempting uninstall: pyade-python\n",
            "    Found existing installation: pyade-python 1.0\n",
            "    Uninstalling pyade-python-1.0:\n",
            "      Successfully uninstalled pyade-python-1.0\n",
            "Successfully installed pyade-python-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#De un diccionario ordenado de fastai a array de parametros\n",
        "def get_params_from_state_dict(state_dict):\n",
        "    return np.concatenate([v.cpu().numpy().ravel() for v in state_dict.values()])\n",
        "\n",
        "def get_params_from_model(model):\n",
        "    return np.concatenate([v.cpu().detach().numpy().ravel() for v in model.parameters()])\n",
        "\n",
        "\n",
        "#De array de parametros a diccionario ordenado\n",
        "def set_params_to_state_dict(params):\n",
        "    state_dict = LEARN.model.state_dict()\n",
        "    offset = 0\n",
        "    for key, param in state_dict.items():\n",
        "        param_size = param.numel()\n",
        "        state_dict[key] = torch.tensor(params[offset:offset + param_size]).view(param.size())\n",
        "        offset += param_size\n",
        "    return state_dict\n",
        "\n",
        "\n",
        "#Funcion de error que recibe un array de parametros\n",
        "def err_arr(params):\n",
        "    weights = set_params_to_state_dict(params)\n",
        "    LEARN.model.load_state_dict(weights)\n",
        "    LEARN.train()\n",
        "    preds, targ, losses = LEARN.get_preds(dl=dls.train, with_loss=True)\n",
        "\n",
        "    return losses.mean().item()\n",
        "\n",
        "\n",
        "def set_params_to_model(params):\n",
        "    offset = 0\n",
        "    for param in LEARN.model.parameters():\n",
        "        param_size = param.numel()\n",
        "        param.data = torch.tensor(params[offset:offset + param_size], dtype=param.data.dtype).view(param.size())\n",
        "        param.requires_grad = True\n",
        "        offset += param_size\n",
        "\n",
        "def err_param(params):\n",
        "    set_params_to_model(params)\n",
        "\n",
        "    LEARN.train()\n",
        "    #Option 1: calculate the error per each batch and make the mean\n",
        "\n",
        "    loss =0.0\n",
        "    for batch in dls.train:\n",
        "        # Handle the case where there are no continuous features\n",
        "        x_cont = batch[1] if len(batch) > 1 and batch[1] is not None else None\n",
        "        pred = LEARN.model(batch[0], x_cont)  # Pass both categorical and continuous features (if any)\n",
        "        target = batch[2].squeeze().long()\n",
        "        loss += F.cross_entropy(pred, target)\n",
        "\n",
        "    loss/=len(dls.train)\n",
        "\n",
        "\n",
        "    return loss.mean().item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MB1CwGa01bMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "par = np.concatenate([param.cpu().detach().numpy().ravel() for param in LEARN.model.parameters()])\n",
        "params_flat = get_params_from_state_dict(LEARN.model.state_dict())"
      ],
      "metadata": {
        "id": "NZQmLikvjmbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyade.shade\n",
        "\n",
        "algorithm = pyade.shade\n",
        "\n",
        "def SHADE_ej(population, pop_size, max_evals, dim, prevm_cr=0, prevm_f=0):\n",
        "\n",
        "  population = np.array(population).reshape(pop_size, dim)\n",
        "\n",
        "  params = algorithm.get_default_params(dim=dim)\n",
        "  # We define the boundaries of the variables\n",
        "  params['bounds'] = np.array([[-50, 50]] * dim)\n",
        "\n",
        "  # We indicate the function we want to minimize\n",
        "  params['func'] = err_param\n",
        "\n",
        "  params['population_size']=pop_size\n",
        "\n",
        "\n",
        "\n",
        "  params['seed']=42\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  params['init_pop']=population\n",
        "\n",
        "  params['max_evals']=max_evals\n",
        "\n",
        "\n",
        "  params['prevm_cr']=prevm_cr\n",
        "\n",
        "  params['prevm_f']=prevm_f\n",
        "\n",
        "  return algorithm.apply(**params)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5WeuOBhfiihU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tengo SHADE funcionando. Tengo que hace ILS-SHADE basicamente añadiendo la busqueda local y todo el rollo según el paper de dani molina.\n",
        "\n",
        "- He cambiado el return del shade.py para que devuelva toda la poblacion, todo el vector de fitness y que ademas devuelva los parametros, y que se puedan volver a meter luego para que se siga adaptando. Solo guardo los parametros de las matrices porque son los que guardan los resultados exitosos de los valores, y los que se aprovechan luego en el resto de ejecuciones. Podría rentar meter la ejecucion de SHADE junto con el correspondiente guardado\n",
        "\n",
        "\n",
        "- Tengo funcionando la Búsqueda local con L-BFGS-B. Tengo dos opciones: la implementación con pytorch y la implementación con scipy. La de scipy calcula el gradiente aproximado de un batch y hace bastantes iteraciones (unas 30) mientras que la otra la calcula en minibatches y aplica cambios tras cada mini-batch y solo hace un epoch.\n",
        "\n",
        "- La de PyTorch en principio está más pensada para este tipo de optimizaciones de machine learning. Al principio funcionaba mucho mejor la de PyTorch pero ahora funciona mucho mejor la de ScipY\n",
        "\n",
        "- Sería interesante y justificable usar solo esta búsqueda local en el algoritmo de SHADE-ILS ya que es un método conocido de segundo orden para entrenamiento de modelos.\n",
        "\n",
        "- Cuando vaya a entrenar a resnet18 será complicado por el número de parámetros. Opciones varias son: meter menos búsqueda local en ese momento, buscar un modelo más pequeño, buscar una búsqueda local más accesible, o, en última opción: no hacer SHADE-ILS con resnet18. He probado con el MLP de 15 capas y no tarda demasiado obteniendo resultados aceptables de 0.17 (3 min)\n",
        "\n",
        "- Ejecucion de SHADE-ILS con MLP 15 capas: 14 min\n",
        "\n",
        "- Aun asi puedo investigar un poco el otro tipo de BL: MTS LS\n",
        "\n",
        "# TODO\n",
        "\n",
        "1. AÑADIR la opción del restart a SHADE-ILS: criterio de restart y acciones\n",
        "\n",
        "2. (Opcional) AÑADIR metodo MTS LS. En tal caso tengo que añadir también el criterio para que se aplique o no la LS y cual se aplica.\n",
        "\n",
        "3. FINE-TUNE de parámetros: evaluaciones, num_pob, etc\n",
        "\n",
        "4. REDACTAR la experimentacion detalladamente y enviarsela a pablo.\n",
        "\n",
        "5. PENSAR qué métricas, datos voy a medir y a comparar.\n",
        "\n",
        "6. COMPROBAR cálculo del gradiente y función de error.\n",
        "\n",
        "7. (OPCIONAL) COMPROBAR qué pasa usando la función f\\_min\\_fbgs de minimize de scipy: es en esencia la misma función que la que estoy usando ahora pero no usa ninguna función gradiente: lo hace a través de una aproximación por diferencias finitas. Intuición de lo que va a pasar: si uso minimize() sin pasarle la función gradiente para la aproximación tarda una eternidad (para de 1seg a más de 4min para 32 neuronas)"
      ],
      "metadata": {
        "id": "H2CC2KP334wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BUSQUEDA LOCAL CON LBFGS CON LIBRERIA SCIPY\n",
        "from scipy.optimize import minimize\n",
        "LEARN = tabular_learner(dls, layers=layers)\n",
        "def get_gradient(ind):\n",
        "    set_params_to_model(ind)\n",
        "    LEARN.train()  # Put the model in training mode\n",
        "    batch = dls.train.one_batch()  # Get one batch of data\n",
        "\n",
        "    # Handle the case where there are no continuous features\n",
        "    x_cont = batch[1] if len(batch) > 1 and batch[1] is not None else None\n",
        "\n",
        "    pred = LEARN.model(batch[0], x_cont)  # Pass both categorical and continuous features (if any)\n",
        "\n",
        "    target = batch[2].squeeze().long()\n",
        "\n",
        "\n",
        "    loss = F.cross_entropy(pred, target)  # Calculate loss (assuming target labels are at index 2)\n",
        "    loss.backward()  # Calculate gradients\n",
        "\n",
        "    # Extract gradients into a list\n",
        "    gradients = [param.grad.clone().detach().cpu().numpy().ravel() for param in LEARN.model.parameters()]\n",
        "\n",
        "    # Concatenate gradients into a single 1D array\n",
        "    return np.concatenate(gradients)\n",
        "\n",
        "\n",
        "def LBFGS_SCIPY(ind):\n",
        "    result = minimize(err_param, ind, jac=get_gradient, method='L-BFGS-B')\n",
        "    return result.x, result.fun, result.nfev, result.njev\n"
      ],
      "metadata": {
        "id": "qw66vjIDBZ9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "layers=[64, 32, 8]\n",
        "LEARN =  tabular_learner(dls, layers=layers)\n",
        "\n",
        "\n",
        "\n",
        "def epoch_LBFGS(ind):\n",
        "    optimizer = optim.LBFGS(LEARN.model.parameters(), lr=0.01)\n",
        "    set_params_to_model(ind)\n",
        "    LEARN.train()  # Put the model in training mode\n",
        "\n",
        "\n",
        "    def closure():\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        batch = next(iter(dls.train))  # Get one batch of data\n",
        "        # Handle the case where there are no continuous features\n",
        "        x_cont = batch[1] if len(batch) > 1 and batch[1] is not None else None\n",
        "        output = LEARN.model(batch[0], x_cont)  # Forward pass\n",
        "        target = batch[2].squeeze().long()\n",
        "        loss = F.cross_entropy(output, target)  # Accumulate loss\n",
        "        loss.backward()  # Backward pass after accumulating loss over all batches\n",
        "        return loss\n",
        "\n",
        "    for _ in range(len(dls.train)): # Assuming you want to run for one epoch\n",
        "        optimizer.step(closure)\n",
        "        print(\"EO\")\n",
        "\n",
        "    return get_params_from_model(LEARN)\n",
        "\n",
        "ind=get_params_from_model(LEARN)\n",
        "print(err_param(ind))\n",
        "ind = epoch_LBFGS(ind)\n",
        "print(err_param(ind))"
      ],
      "metadata": {
        "id": "7g371PuTF4tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Algoritmo SHADE-ILS\n",
        "from collections import deque\n",
        "#layers=[1024, 1024,512, 512, 256, 256, 128, 128, 64, 64, 32, 32, 8, 8, 4]\n",
        "layers=[32]\n",
        "LEARN =  tabular_learner(dls, layers=layers)\n",
        "\n",
        "#layers=[32]\n",
        "\n",
        "\n",
        "population_size = 25\n",
        "evals = 0\n",
        "max_evals = 3000\n",
        "max_evals_SHADE = 100\n",
        "prevm_cr=0\n",
        "prevm_f=0\n",
        "must_restart=False\n",
        "improq = deque([1,1,1], maxlen=3)\n",
        "\n",
        "#Initialize the population\n",
        "population = [get_params_from_model(tabular_learner(dls, layers=layers)) for _ in range(population_size)]\n",
        "fitness = [err_param(elem) for elem in population]\n",
        "evals += population_size\n",
        "size_ind=len(population[0])\n",
        "\n",
        "#Select the best\n",
        "\n",
        "current_best_fitness = min(fitness)\n",
        "current_best_index = fitness.index(current_best_fitness)\n",
        "current_best = population[current_best_index]\n",
        "\n",
        "temp_current_best, temp_current_best_fitness, e1, e2 = LBFGS_SCIPY(current_best)\n",
        "evals += e1 + e2\n",
        "\n",
        "improq.append((current_best_fitness-temp_current_best_fitness)/current_best_fitness)\n",
        "\n",
        "if temp_current_best_fitness < current_best_fitness:\n",
        "  current_best_fitness = temp_current_best_fitness\n",
        "  current_best = temp_current_best\n",
        "\n",
        "\n",
        "population[current_best_index] = current_best\n",
        "fitness[current_best_index] = current_best_fitness\n",
        "\n",
        "best_solution=current_best\n",
        "best_fitness=current_best_fitness\n",
        "\n",
        "while evals < max_evals:\n",
        "  print(\"eo\")\n",
        "  population, fitness, prevm_cr, prevm_f = SHADE_ej(population, population_size, max_evals_SHADE, size_ind, prevm_cr=prevm_cr, prevm_f=prevm_f)\n",
        "  evals += max_evals_SHADE\n",
        "  temp_current_best_fitness= min(fitness)\n",
        "\n",
        "  improq.append((current_best_fitness-temp_current_best_fitness)/current_best_fitness)\n",
        "\n",
        "  if temp_current_best_fitness < current_best_fitness:\n",
        "    current_best_fitness = temp_current_best_fitness\n",
        "    current_best_index = list(fitness).index(current_best_fitness)\n",
        "    current_best = population[current_best_index]\n",
        "\n",
        "\n",
        "\n",
        "  print(improq)\n",
        "  if np.all(np.array(improq)<0.05):\n",
        "    must_restart=True\n",
        "\n",
        "  #Choose the LS method to apply this iteration based on improvement\n",
        "\n",
        "  temp_current_best, temp_current_best_fitness, e1, e2 = LBFGS_SCIPY(current_best)\n",
        "  evals += e1 + e2\n",
        "\n",
        "  improq.append((current_best_fitness-temp_current_best_fitness)/current_best_fitness)\n",
        "\n",
        "  if temp_current_best_fitness < current_best_fitness:\n",
        "    current_best_fitness = temp_current_best_fitness\n",
        "    current_best = temp_current_best\n",
        "\n",
        "\n",
        "  print(improq)\n",
        "  if np.all(np.array(improq)<0.05):\n",
        "    must_restart=True\n",
        "\n",
        "  population[current_best_index] = current_best\n",
        "  fitness[current_best_index] = current_best_fitness\n",
        "\n",
        "  #Update the probability to apply LS in next iterations\n",
        "\n",
        "  if current_best_fitness < best_fitness:\n",
        "    best_fitness = np.copy(current_best_fitness)\n",
        "    best_solution = np.copy(current_best)\n",
        "\n",
        "  if must_restart:\n",
        "    random_index = np.random.choice(population_size)\n",
        "    sol = population[random_index]\n",
        "    sol += np.random.normal(0, 100, len(sol))\n",
        "\n",
        "    population = [get_params_from_model(tabular_learner(dls, layers=layers)) for _ in range(population_size-1)]\n",
        "    fitness = [err_param(elem) for elem in population]\n",
        "    evals += population_size\n",
        "    population.append(sol)\n",
        "    current_best_fitness=err_param(sol)\n",
        "    current_best=sol\n",
        "    fitness.append(current_best_fitness)\n",
        "    improq=deque([1,1,1], maxlen=3)\n",
        "\n",
        "    print(\"Reiniciado\")\n",
        "    must_restart=False\n"
      ],
      "metadata": {
        "id": "CKGpAwT2n-ME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8485cb34-50d9-4a6d-e82f-996c3997f550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eo\n",
            "deque([1, 0.5873470962560707, 0.40669233524140797], maxlen=3)\n",
            "deque([0.5873470962560707, 0.40669233524140797, 0.07956459098364536], maxlen=3)\n",
            "eo\n",
            "deque([0.40669233524140797, 0.07956459098364536, 0.09693808393611848], maxlen=3)\n",
            "deque([0.07956459098364536, 0.09693808393611848, -0.106735860275979], maxlen=3)\n",
            "eo\n",
            "deque([0.09693808393611848, -0.106735860275979, 0.0], maxlen=3)\n",
            "deque([-0.106735860275979, 0.0, -0.35898917922362844], maxlen=3)\n",
            "Reiniciado\n",
            "eo\n",
            "deque([1, 1, 0.9999785176510713], maxlen=3)\n",
            "deque([1, 0.9999785176510713, 0.56348202421379], maxlen=3)\n",
            "eo\n",
            "deque([0.9999785176510713, 0.56348202421379, 0.13888879258625697], maxlen=3)\n",
            "deque([0.56348202421379, 0.13888879258625697, -0.008993162160511393], maxlen=3)\n",
            "eo\n",
            "deque([0.13888879258625697, -0.008993162160511393, 0.05285602593810888], maxlen=3)\n",
            "deque([-0.008993162160511393, 0.05285602593810888, -0.23086261165990693], maxlen=3)\n",
            "eo\n",
            "deque([0.05285602593810888, -0.23086261165990693, -0.03924239219686979], maxlen=3)\n",
            "deque([-0.23086261165990693, -0.03924239219686979, -0.30696417759420075], maxlen=3)\n",
            "Reiniciado\n",
            "eo\n",
            "deque([1, 1, 0.9999919977712921], maxlen=3)\n",
            "deque([1, 0.9999919977712921, -0.013009119560697979], maxlen=3)\n",
            "eo\n",
            "deque([0.9999919977712921, -0.013009119560697979, 0.19994111147890203], maxlen=3)\n",
            "deque([-0.013009119560697979, 0.19994111147890203, -0.18339186778331806], maxlen=3)\n",
            "eo\n",
            "deque([0.19994111147890203, -0.18339186778331806, 0.2739960945973627], maxlen=3)\n",
            "deque([-0.18339186778331806, 0.2739960945973627, -0.1751890512485174], maxlen=3)\n",
            "eo\n",
            "deque([0.2739960945973627, -0.1751890512485174, 0.16086318509370548], maxlen=3)\n",
            "deque([-0.1751890512485174, 0.16086318509370548, -0.4385794394667511], maxlen=3)\n",
            "eo\n",
            "deque([0.16086318509370548, -0.4385794394667511, 0.13721350812628813], maxlen=3)\n",
            "deque([-0.4385794394667511, 0.13721350812628813, -0.8277135705545458], maxlen=3)\n",
            "eo\n",
            "deque([0.13721350812628813, -0.8277135705545458, -0.09009009413668986], maxlen=3)\n",
            "deque([-0.8277135705545458, -0.09009009413668986, -0.7812976937054482], maxlen=3)\n",
            "Reiniciado\n",
            "eo\n",
            "deque([1, 1, 0.9999810277497646], maxlen=3)\n",
            "deque([1, 0.9999810277497646, -0.09723936772335107], maxlen=3)\n",
            "eo\n",
            "deque([0.9999810277497646, -0.09723936772335107, 0.07804272859144701], maxlen=3)\n",
            "deque([-0.09723936772335107, 0.07804272859144701, -0.0377425990437737], maxlen=3)\n",
            "eo\n",
            "deque([0.07804272859144701, -0.0377425990437737, 0.22698576282236468], maxlen=3)\n",
            "deque([-0.0377425990437737, 0.22698576282236468, -0.03054051163148262], maxlen=3)\n",
            "eo\n",
            "deque([0.22698576282236468, -0.03054051163148262, 0.2345376422137965], maxlen=3)\n",
            "deque([-0.03054051163148262, 0.2345376422137965, -0.08246045984658162], maxlen=3)\n",
            "eo\n",
            "deque([0.2345376422137965, -0.08246045984658162, 0.2799139015001779], maxlen=3)\n",
            "deque([-0.08246045984658162, 0.2799139015001779, -0.23888708908799522], maxlen=3)\n",
            "eo\n",
            "deque([0.2799139015001779, -0.23888708908799522, -0.020615617866274256], maxlen=3)\n",
            "deque([-0.23888708908799522, -0.020615617866274256, -0.23888934555478727], maxlen=3)\n",
            "Reiniciado\n",
            "eo\n",
            "deque([1, 1, 0.9999883430297675], maxlen=3)\n",
            "deque([1, 0.9999883430297675, 0.03728820135932858], maxlen=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fitness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CLGMKNvNoSi",
        "outputId": "4494d513-0bf9-4b21-d27e-655be32e051a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.90693063e-01 4.29877877e-01 4.83357102e-01 4.05508637e-01\n",
            " 5.36503375e-01 3.84969562e-01 4.46414798e-01 2.73586065e-01\n",
            " 6.98655605e-01 5.24204969e-01 4.42965508e-01 4.32018399e-01\n",
            " 7.27365792e-01 6.29636586e-01 5.93505919e-01 6.76367044e-01\n",
            " 4.07230705e-01 4.44136024e-01 7.54291952e-01 5.67448914e-01\n",
            " 5.35882771e-01 4.22633529e-01 6.19049489e-01 6.22650683e-01\n",
            " 6.73533740e+03]\n"
          ]
        }
      ]
    }
  ]
}