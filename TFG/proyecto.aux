\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\abx@aux@refcontext{anyt/global//global/global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {section}{Agradecimientos}{\es@scroman  {iv}}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Índice de Figuras}{\es@scroman  {ix}}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Índice de Tablas}{\es@scroman  {xi}}{section*.5}\protected@file@percent }
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\@writefile{toc}{\contentsline {section}{Resumen}{\es@scroman  {xii}}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Parte matemática: análisis del gradiente descendente, su convergencia y \textit  {backpropagation}}{1}{part.1}\protected@file@percent }
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{mitchell1997machine}
\abx@aux@segm{0}{0}{mitchell1997machine}
\abx@aux@cite{0}{lecun2015deep}
\abx@aux@segm{0}{0}{lecun2015deep}
\abx@aux@cite{0}{NIPS2012_c399862d}
\abx@aux@segm{0}{0}{NIPS2012_c399862d}
\abx@aux@cite{0}{Sejnowski18}
\abx@aux@segm{0}{0}{Sejnowski18}
\abx@aux@cite{0}{lecunnDeepForAI}
\abx@aux@segm{0}{0}{lecunnDeepForAI}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{CauchyGD}
\abx@aux@segm{0}{0}{CauchyGD}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introducción}{2}{section.1}\protected@file@percent }
\abx@aux@cite{0}{rumelbackprop}
\abx@aux@segm{0}{0}{rumelbackprop}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{patternrecog}
\abx@aux@segm{0}{0}{patternrecog}
\abx@aux@cite{0}{EffBackProp}
\abx@aux@segm{0}{0}{EffBackProp}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{alternativabacknumerical}
\abx@aux@segm{0}{0}{alternativabacknumerical}
\abx@aux@cite{0}{alternativabackprop1}
\abx@aux@segm{0}{0}{alternativabackprop1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Ejemplo del proceso de optimización mediante el algoritmo de gradiente descendente}}{3}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1.GD}{{1}{3}{Ejemplo del proceso de optimización mediante el algoritmo de gradiente descendente}{figure.caption.7}{}}
\newlabel{fig:1.GD@cref}{{[figure][1][]1}{[1][3][]3}{}{}{}}
\abx@aux@cite{0}{AutomaticDiff}
\abx@aux@segm{0}{0}{AutomaticDiff}
\abx@aux@cite{0}{NPHardProblem}
\abx@aux@segm{0}{0}{NPHardProblem}
\abx@aux@cite{0}{Problem3_accel}
\abx@aux@segm{0}{0}{Problem3_accel}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivación}{4}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objetivos}{5}{subsection.1.2}\protected@file@percent }
\abx@aux@cite{0}{pml1Book}
\abx@aux@segm{0}{0}{pml1Book}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{toc}{\contentsline {section}{\numberline {2}Fundamentos previos}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Cálculo diferencial}{6}{subsection.2.1}\protected@file@percent }
\newlabel{eq:deslipsint}{{1}{8}{Función Lipschitziana}{equation.2.1}{}}
\newlabel{eq:deslipsint@cref}{{[equation][1][]1}{[1][8][]8}{}{}{}}
\abx@aux@cite{0}{axler2024linear}
\abx@aux@segm{0}{0}{axler2024linear}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Algunos conceptos sobre álgebra lineal}{9}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Algunos conceptos sobre probabilidad}{10}{subsection.2.3}\protected@file@percent }
\newlabel{def:esprob}{{2.13}{10}{Espacio de probabilidad}{resultado.2.13}{}}
\newlabel{def:esprob@cref}{{[subsection][3][2]2.3}{[1][10][]10}{}{}{}}
\abx@aux@cite{0}{Curry1944GDNoLin}
\abx@aux@segm{0}{0}{Curry1944GDNoLin}
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\abx@aux@cite{0}{CauchyGD}
\abx@aux@segm{0}{0}{CauchyGD}
\@writefile{toc}{\contentsline {section}{\numberline {3}Gradiente Descendente}{14}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Evolución del número de artículos indexados anualmente en la base de datos Scopus relacionados con optimización y aprendizaje mediante métodos de descenso de gradiente}}{15}{figure.caption.8}\protected@file@percent }
\newlabel{fig:mat_scopus_gd}{{2}{15}{Evolución del número de artículos indexados anualmente en la base de datos Scopus relacionados con optimización y aprendizaje mediante métodos de descenso de gradiente}{figure.caption.8}{}}
\newlabel{fig:mat_scopus_gd@cref}{{[figure][2][]2}{[1][14][]15}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Gradiente descendente de Cauchy}{15}{subsection.3.1}\protected@file@percent }
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Gradiente descendente en el entrenamiento de modelos}{16}{subsection.3.2}\protected@file@percent }
\newlabel{eq:GD}{{4}{16}{Gradiente descendente en el entrenamiento de modelos}{equation.3.4}{}}
\newlabel{eq:GD@cref}{{[equation][4][]4}{[1][16][]16}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Estrategias de gradiente descendente}{16}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{sec:estrategias}{{3.2.1}{16}{Estrategias de gradiente descendente}{subsubsection.3.2.1}{}}
\newlabel{sec:estrategias@cref}{{[subsubsection][1][3,2]3.2.1}{[1][16][]16}{}{}{}}
\newlabel{eq:SGD}{{5}{17}{Estrategias de gradiente descendente}{equation.3.5}{}}
\newlabel{eq:SGD@cref}{{[equation][5][]5}{[1][17][]17}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}\textit  {Learning rate}}{17}{subsubsection.3.2.2}\protected@file@percent }
\abx@aux@cite{0}{Mostafa2012}
\abx@aux@segm{0}{0}{Mostafa2012}
\abx@aux@cite{0}{Mostafa2012}
\abx@aux@segm{0}{0}{Mostafa2012}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Efecto del tamaño del \textit  {learning rate} en el comportamiento del algoritmo de gradiente descendente}}{18}{figure.caption.9}\protected@file@percent }
\newlabel{fig:lr}{{3}{18}{Efecto del tamaño del \textit {learning rate} en el comportamiento del algoritmo de gradiente descendente}{figure.caption.9}{}}
\newlabel{fig:lr@cref}{{[figure][3][]3}{[1][18][]18}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Subgradientes}{18}{subsection.3.3}\protected@file@percent }
\newlabel{sec:subgrad}{{3.3}{18}{Subgradientes}{subsection.3.3}{}}
\newlabel{sec:subgrad@cref}{{[subsection][3][3]3.3}{[1][18][]18}{}{}{}}
\abx@aux@cite{0}{EffBackProp}
\abx@aux@segm{0}{0}{EffBackProp}
\abx@aux@cite{0}{figRelu1}
\abx@aux@segm{0}{0}{figRelu1}
\abx@aux@cite{0}{figRelu1}
\abx@aux@segm{0}{0}{figRelu1}
\abx@aux@cite{0}{convexSubgrad}
\abx@aux@segm{0}{0}{convexSubgrad}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Funciones de activación basadas en ReLU y su impacto en la optimización mediante gradiente descendente}}{20}{figure.caption.10}\protected@file@percent }
\newlabel{fig:3.ReLU}{{4}{20}{Funciones de activación basadas en ReLU y su impacto en la optimización mediante gradiente descendente}{figure.caption.10}{}}
\newlabel{fig:3.ReLU@cref}{{[figure][4][]4}{[1][19][]20}{}{}{}}
\newlabel{prop:subgrad}{{3.4}{22}{Existencia de subgradientes}{resultado.3.4}{}}
\newlabel{prop:subgrad@cref}{{[subsection][3][3]3.3}{[1][22][]22}{}{}{}}
\newlabel{eq:des2}{{6}{23}{Subgradientes}{equation.3.6}{}}
\newlabel{eq:des2@cref}{{[equation][6][]6}{[1][23][]23}{}{}{}}
\newlabel{proof1:f(x)}{{7}{23}{Subgradientes}{equation.3.7}{}}
\newlabel{proof1:f(x)@cref}{{[equation][7][]7}{[1][23][]23}{}{}{}}
\newlabel{proof1:f(y)}{{8}{23}{Subgradientes}{equation.3.8}{}}
\newlabel{proof1:f(y)@cref}{{[equation][8][]8}{[1][23][]23}{}{}{}}
\newlabel{proof1:epi}{{9}{24}{Subgradientes}{equation.3.9}{}}
\newlabel{proof1:epi@cref}{{[equation][9][]9}{[1][24][]24}{}{}{}}
\abx@aux@cite{0}{ReLuat0}
\abx@aux@segm{0}{0}{ReLuat0}
\abx@aux@cite{0}{optimal_gd}
\abx@aux@segm{0}{0}{optimal_gd}
\abx@aux@cite{0}{de2015global}
\abx@aux@segm{0}{0}{de2015global}
\abx@aux@cite{0}{mertikopoulos2020almost}
\abx@aux@segm{0}{0}{mertikopoulos2020almost}
\abx@aux@cite{0}{fehrman2020convergence}
\abx@aux@segm{0}{0}{fehrman2020convergence}
\abx@aux@cite{0}{tibshirani2013convex}
\abx@aux@segm{0}{0}{tibshirani2013convex}
\newlabel{ej:RELUsub}{{3.6}{25}{Subgradiente de la función ReLU}{resultado.3.6}{}}
\newlabel{ej:RELUsub@cref}{{[subsection][3][3]3.3}{[1][24][]25}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Convergencia}{25}{subsection.3.4}\protected@file@percent }
\newlabel{sec:convergencia}{{3.4}{25}{Convergencia}{subsection.3.4}{}}
\newlabel{sec:convergencia@cref}{{[subsection][4][3]3.4}{[1][25][]25}{}{}{}}
\abx@aux@cite{0}{LiVisualizing}
\abx@aux@segm{0}{0}{LiVisualizing}
\abx@aux@cite{0}{Ahmadi_2011_NP_Convex}
\abx@aux@segm{0}{0}{Ahmadi_2011_NP_Convex}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Convergencia para \textit  {Batch Gradient Descent}}{26}{subsubsection.3.4.1}\protected@file@percent }
\newlabel{prop:hess}{{3.7}{26}{Convergencia para \textit {Batch Gradient Descent}}{resultado.3.7}{}}
\newlabel{prop:hess@cref}{{[subsubsection][1][3,4]3.4.1}{[1][26][]26}{}{}{}}
\newlabel{eq:acotporL}{{10}{27}{Convergencia para \textit {Batch Gradient Descent}}{equation.3.10}{}}
\newlabel{eq:acotporL@cref}{{[equation][10][]10}{[1][27][]27}{}{}{}}
\newlabel{proof:gdconvex}{{3.9}{28}{Convergencia para BGD}{resultado.3.9}{}}
\newlabel{proof:gdconvex@cref}{{[subsubsection][1][3,4]3.4.1}{[1][27][]28}{}{}{}}
\newlabel{eq:gdproof1}{{11}{29}{Convergencia para \textit {Batch Gradient Descent}}{equation.3.11}{}}
\newlabel{eq:gdproof1@cref}{{[equation][11][]11}{[1][29][]29}{}{}{}}
\abx@aux@cite{0}{stochastic}
\abx@aux@segm{0}{0}{stochastic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Convergencia para versiones estocásticas}{30}{subsubsection.3.4.2}\protected@file@percent }
\newlabel{eq:martingala}{{12}{31}{Convergencia para versiones estocásticas}{equation.3.12}{}}
\newlabel{eq:martingala@cref}{{[equation][12][]12}{[1][31][]31}{}{}{}}
\newlabel{teor:convdoob}{{3.10}{32}{Teorema de Convergencia de Supermartingalas}{resultado.3.10}{}}
\newlabel{teor:convdoob@cref}{{[subsubsection][2][3,4]3.4.2}{[1][32][]32}{}{}{}}
\newlabel{teor:sig}{{3.11}{32}{Teorema de Robbins-Siegmund}{resultado.3.11}{}}
\newlabel{teor:sig@cref}{{[subsubsection][2][3,4]3.4.2}{[1][32][]32}{}{}{}}
\newlabel{eq:rb_eq1}{{14}{32}{Convergencia para versiones estocásticas}{equation.3.14}{}}
\newlabel{eq:rb_eq1@cref}{{[equation][14][]14}{[1][32][]32}{}{}{}}
\newlabel{eq:sig1}{{15}{35}{Convergencia para versiones estocásticas}{equation.3.15}{}}
\newlabel{eq:sig1@cref}{{[equation][15][]15}{[1][34][]35}{}{}{}}
\newlabel{teor:convsgd}{{3.13}{35}{Convergencia de algoritmos SGD}{resultado.3.13}{}}
\newlabel{teor:convsgd@cref}{{[subsubsection][2][3,4]3.4.2}{[1][35][]35}{}{}{}}
\newlabel{eq:convsgd1}{{16}{35}{Convergencia de algoritmos SGD}{equation.3.16}{}}
\newlabel{eq:convsgd1@cref}{{[equation][16][]16}{[1][35][]35}{}{}{}}
\newlabel{eq:convsgd2}{{17}{35}{Convergencia de algoritmos SGD}{equation.3.17}{}}
\newlabel{eq:convsgd2@cref}{{[equation][17][]17}{[1][35][]35}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Problemas en la convergencia}{36}{subsubsection.3.4.3}\protected@file@percent }
\abx@aux@cite{0}{NIPS2014_17e23e50}
\abx@aux@segm{0}{0}{NIPS2014_17e23e50}
\abx@aux@cite{0}{AutomaticDiff}
\abx@aux@segm{0}{0}{AutomaticDiff}
\@writefile{toc}{\contentsline {section}{\numberline {4}\textit  {Backpropagation}}{38}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Diferenciación automática}{38}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Diferenciación hacia delante vs hacia atrás}{39}{subsection.4.2}\protected@file@percent }
\abx@aux@cite{0}{bishop2023learning}
\abx@aux@segm{0}{0}{bishop2023learning}
\abx@aux@cite{0}{bishop2023learning}
\abx@aux@segm{0}{0}{bishop2023learning}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Diferenciación hacia delante}}{41}{algorithm.1}\protected@file@percent }
\newlabel{alg:fowdiff}{{1}{41}{Diferenciación hacia delante}{algorithm.1}{}}
\newlabel{alg:fowdiff@cref}{{[algorithm][1][]1}{[1][41][]41}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Diferenciación en modo reverso}}{42}{algorithm.2}\protected@file@percent }
\newlabel{alg:backdif}{{2}{42}{Diferenciación en modo reverso}{algorithm.2}{}}
\newlabel{alg:backdif@cref}{{[algorithm][2][]2}{[1][41][]42}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Cálculo del error para una unidad oculta ilustando la propagación hacia delante y la propagación hacia atrás del error}}{42}{figure.caption.11}\protected@file@percent }
\newlabel{fig:bp_1}{{5}{42}{Cálculo del error para una unidad oculta ilustando la propagación hacia delante y la propagación hacia atrás del error}{figure.caption.11}{}}
\newlabel{fig:bp_1@cref}{{[figure][5][]5}{[1][41][]42}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\textit  {Backpropagation} en perceptrones multicapa}{43}{subsection.4.3}\protected@file@percent }
\abx@aux@cite{0}{bishop2023learning}
\abx@aux@segm{0}{0}{bishop2023learning}
\abx@aux@cite{0}{bishop2023learning}
\abx@aux@segm{0}{0}{bishop2023learning}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces BP para MLP con k capas}}{44}{algorithm.3}\protected@file@percent }
\newlabel{alg:BPMLPk}{{3}{44}{BP para MLP con k capas}{algorithm.3}{}}
\newlabel{alg:BPMLPk@cref}{{[algorithm][3][]3}{[1][44][]44}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Proceso de \textit  {backpropagation} en una arquitectura modular de aprendizaje profundo}}{45}{figure.caption.12}\protected@file@percent }
\newlabel{fig:bp_2}{{6}{45}{Proceso de \textit {backpropagation} en una arquitectura modular de aprendizaje profundo}{figure.caption.12}{}}
\newlabel{fig:bp_2@cref}{{[figure][6][]6}{[1][44][]45}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Capa no-lineal}{45}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Capa de entropía cruzada}{46}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Capa lineal}{47}{subsubsection.4.3.3}\protected@file@percent }
\abx@aux@cite{0}{pml1Book}
\abx@aux@segm{0}{0}{pml1Book}
\abx@aux@cite{0}{pml1Book}
\abx@aux@segm{0}{0}{pml1Book}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Representación de una red computacional como un grafo dirigido acíclico para diferenciación automática y \textit  {backpropagation}}}{48}{figure.caption.13}\protected@file@percent }
\newlabel{fig:def.grafo}{{7}{48}{Representación de una red computacional como un grafo dirigido acíclico para diferenciación automática y \textit {backpropagation}}{figure.caption.13}{}}
\newlabel{fig:def.grafo@cref}{{[figure][7][]7}{[1][48][]48}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Grafos computacionales}{48}{subsubsection.4.3.4}\protected@file@percent }
\abx@aux@cite{0}{VanishExplode}
\abx@aux@segm{0}{0}{VanishExplode}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Problemas con el cálculo del gradiente}{49}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Desvanecimiento y explosión del gradiente}{49}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{sec:desvyexpl}{{4.4.1}{49}{Desvanecimiento y explosión del gradiente}{subsubsection.4.4.1}{}}
\newlabel{sec:desvyexpl@cref}{{[subsubsection][1][4,4]4.4.1}{[1][49][]49}{}{}{}}
\abx@aux@cite{0}{stabilityProblem2}
\abx@aux@segm{0}{0}{stabilityProblem2}
\abx@aux@cite{0}{stabilityProblem2}
\abx@aux@segm{0}{0}{stabilityProblem2}
\abx@aux@cite{0}{heinic}
\abx@aux@segm{0}{0}{heinic}
\abx@aux@cite{0}{pml1Book}
\abx@aux@segm{0}{0}{pml1Book}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Inicialización de los pesos}{51}{subsubsection.4.4.2}\protected@file@percent }
\newlabel{sec:inipesos}{{4.4.2}{51}{Inicialización de los pesos}{subsubsection.4.4.2}{}}
\newlabel{sec:inipesos@cref}{{[subsubsection][2][4,4]4.4.2}{[1][50][]51}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusiones y trabajos futuros}{53}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Parte informática: Estudio empírico comparativo entre gradiente descendiente y metaheurísticas para el entrenamiento de redes neuronales profundas}{54}{part.2}\protected@file@percent }
\abx@aux@cite{0}{Mculloch43}
\abx@aux@segm{0}{0}{Mculloch43}
\abx@aux@cite{0}{patternrecog}
\abx@aux@segm{0}{0}{patternrecog}
\abx@aux@cite{0}{pml1Book}
\abx@aux@segm{0}{0}{pml1Book}
\abx@aux@cite{0}{Mostafa2012}
\abx@aux@segm{0}{0}{Mostafa2012}
\abx@aux@cite{0}{lecun2015deep}
\abx@aux@segm{0}{0}{lecun2015deep}
\abx@aux@cite{0}{SCHMIDHUBER201585}
\abx@aux@segm{0}{0}{SCHMIDHUBER201585}
\abx@aux@cite{0}{bishop2023learning}
\abx@aux@segm{0}{0}{bishop2023learning}
\abx@aux@cite{0}{prince2023understanding}
\abx@aux@segm{0}{0}{prince2023understanding}
\abx@aux@cite{0}{2016modernapp}
\abx@aux@segm{0}{0}{2016modernapp}
\abx@aux@cite{0}{lecun2015deep}
\abx@aux@segm{0}{0}{lecun2015deep}
\abx@aux@cite{0}{bishop2023learning}
\abx@aux@segm{0}{0}{bishop2023learning}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{toc}{\contentsline {section}{\numberline {6}Introducción}{56}{section.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Aclaración de la diferencia entre el algoritmo de gradiente descendente y \textit  {backpropagation}}}{56}{figure.caption.14}\protected@file@percent }
\newlabel{fig:gd_bp}{{8}{56}{Aclaración de la diferencia entre el algoritmo de gradiente descendente y \textit {backpropagation}}{figure.caption.14}{}}
\newlabel{fig:gd_bp@cref}{{[figure][8][]8}{[1][56][]56}{}{}{}}
\abx@aux@cite{0}{ConvexOp}
\abx@aux@segm{0}{0}{ConvexOp}
\abx@aux@cite{0}{Curry1944GDNoLin}
\abx@aux@segm{0}{0}{Curry1944GDNoLin}
\abx@aux@cite{0}{rumelbackprop}
\abx@aux@segm{0}{0}{rumelbackprop}
\abx@aux@cite{0}{EffBackProp}
\abx@aux@segm{0}{0}{EffBackProp}
\abx@aux@cite{0}{NIPS2014_17e23e50}
\abx@aux@segm{0}{0}{NIPS2014_17e23e50}
\abx@aux@cite{0}{stabilityProblem2}
\abx@aux@segm{0}{0}{stabilityProblem2}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Esquema general de la parte Informática de este TFG con los objetivos parciales a abordar en el mismo}}{57}{figure.caption.15}\protected@file@percent }
\newlabel{fig:esquema}{{9}{57}{Esquema general de la parte Informática de este TFG con los objetivos parciales a abordar en el mismo}{figure.caption.15}{}}
\newlabel{fig:esquema@cref}{{[figure][9][]9}{[1][57][]57}{}{}{}}
\abx@aux@cite{0}{mhhandbook}
\abx@aux@segm{0}{0}{mhhandbook}
\abx@aux@cite{0}{MH_desing_imp}
\abx@aux@segm{0}{0}{MH_desing_imp}
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\abx@aux@cite{0}{Adam}
\abx@aux@segm{0}{0}{Adam}
\abx@aux@cite{0}{Nesterov}
\abx@aux@segm{0}{0}{Nesterov}
\abx@aux@cite{0}{rmsprop}
\abx@aux@segm{0}{0}{rmsprop}
\abx@aux@cite{0}{AdamW}
\abx@aux@segm{0}{0}{AdamW}
\abx@aux@cite{0}{shade}
\abx@aux@segm{0}{0}{shade}
\abx@aux@cite{0}{shadeils}
\abx@aux@segm{0}{0}{shadeils}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Tabla comparativa entre las técnicas clásicas basadas en gradiente, las metaheurísticas y las dos propuestas algorítmicas propias (SHADE-GD y SHADE-ILS-GD)}}{59}{table.caption.16}\protected@file@percent }
\newlabel{tab:comp_propias}{{1}{59}{Tabla comparativa entre las técnicas clásicas basadas en gradiente, las metaheurísticas y las dos propuestas algorítmicas propias (SHADE-GD y SHADE-ILS-GD)}{table.caption.16}{}}
\newlabel{tab:comp_propias@cref}{{[table][1][]1}{[1][58][]59}{}{}{}}
\abx@aux@cite{0}{NIPS2014_17e23e50}
\abx@aux@segm{0}{0}{NIPS2014_17e23e50}
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Motivación}{60}{subsection.6.1}\protected@file@percent }
\newlabel{sec:motinfo}{{6.1}{60}{Motivación}{subsection.6.1}{}}
\newlabel{sec:motinfo@cref}{{[subsection][1][6]6.1}{[1][60][]60}{}{}{}}
\abx@aux@cite{0}{IngSoft}
\abx@aux@segm{0}{0}{IngSoft}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Objetivos}{61}{subsection.6.2}\protected@file@percent }
\newlabel{sec:objinf}{{6.2}{61}{Objetivos}{subsection.6.2}{}}
\newlabel{sec:objinf@cref}{{[subsection][2][6]6.2}{[1][60][]61}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Planificación}{61}{subsection.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Planificación de la parte Informática del presente TFG en modelo de cascada retroalimentada}}{63}{figure.caption.17}\protected@file@percent }
\newlabel{fig:modcas}{{10}{63}{Planificación de la parte Informática del presente TFG en modelo de cascada retroalimentada}{figure.caption.17}{}}
\newlabel{fig:modcas@cref}{{[figure][10][]10}{[1][62][]63}{}{}{}}
\newlabel{fig:plan1}{{11a}{64}{Subfigure 11a}{subfigure.11.1}{}}
\newlabel{sub@fig:plan1}{{(a)}{a}{Subfigure 11a\relax }{subfigure.11.1}{}}
\newlabel{fig:plan1@cref}{{[subfigure][1][11]11a}{[1][62][]64}{}{}{}}
\newlabel{fig:plan2}{{11b}{64}{Subfigure 11b}{subfigure.11.2}{}}
\newlabel{sub@fig:plan2}{{(b)}{b}{Subfigure 11b\relax }{subfigure.11.2}{}}
\newlabel{fig:plan2@cref}{{[subfigure][2][11]11b}{[1][62][]64}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Diagramas de Gantt de la planificación inicial y final del proyecto}}{64}{figure.caption.18}\protected@file@percent }
\newlabel{fig:planesjunto}{{11}{64}{Diagramas de Gantt de la planificación inicial y final del proyecto}{figure.caption.18}{}}
\newlabel{fig:planesjunto@cref}{{[figure][11][]11}{[1][62][]64}{}{}{}}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{perceptron}
\abx@aux@segm{0}{0}{perceptron}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\@writefile{toc}{\contentsline {section}{\numberline {7}Fundamentos teóricos}{65}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Redes neuronales y aprendizaje profundo}{65}{subsection.7.1}\protected@file@percent }
\newlabel{sec:profundo}{{7.1}{65}{Redes neuronales y aprendizaje profundo}{subsection.7.1}{}}
\newlabel{sec:profundo@cref}{{[subsection][1][7]7.1}{[1][65][]65}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Red neuronal}{65}{subsubsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Aprendizaje profundo y redes neuronales profundas}{65}{subsubsection.7.1.2}\protected@file@percent }
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Representación esquemática de una neurona artificial inspirada en el modelo biológico}}{66}{figure.caption.19}\protected@file@percent }
\newlabel{fig:Perceptron}{{12}{66}{Representación esquemática de una neurona artificial inspirada en el modelo biológico}{figure.caption.19}{}}
\newlabel{fig:Perceptron@cref}{{[figure][12][]12}{[1][65][]66}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Perceptrones Multicapa}{66}{subsubsection.7.1.3}\protected@file@percent }
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Estructura de una red neuronal profunda con dos capas ocultas}}{67}{figure.caption.20}\protected@file@percent }
\newlabel{fig:NeuralNet}{{13}{67}{Estructura de una red neuronal profunda con dos capas ocultas}{figure.caption.20}{}}
\newlabel{fig:NeuralNet@cref}{{[figure][13][]13}{[1][67][]67}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Redes convolucionales}{67}{subsection.7.2}\protected@file@percent }
\newlabel{sec:convnets}{{7.2}{67}{Redes convolucionales}{subsection.7.2}{}}
\newlabel{sec:convnets@cref}{{[subsection][2][7]7.2}{[1][67][]67}{}{}{}}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Operación de convolución}{68}{subsubsection.7.2.1}\protected@file@percent }
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Operación de correlación cruzada en una red neuronal convolucional}}{69}{figure.caption.21}\protected@file@percent }
\newlabel{fig:3.Conv}{{14}{69}{Operación de correlación cruzada en una red neuronal convolucional}{figure.caption.21}{}}
\newlabel{fig:3.Conv@cref}{{[figure][14][]14}{[1][68][]69}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Capa Convolucional}{69}{subsubsection.7.2.2}\protected@file@percent }
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{batchnorm}
\abx@aux@segm{0}{0}{batchnorm}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\newlabel{eq:output}{{18}{70}{Capa Convolucional}{equation.7.18}{}}
\newlabel{eq:output@cref}{{[equation][18][]18}{[1][70][]70}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}Capa \textit  {Pooling}}{70}{subsubsection.7.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Proceso de convolución en una red neuronal convolucional}}{71}{figure.caption.22}\protected@file@percent }
\newlabel{fig:stride}{{15}{71}{Proceso de convolución en una red neuronal convolucional}{figure.caption.22}{}}
\newlabel{fig:stride@cref}{{[figure][15][]15}{[1][70][]71}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Ejemplo de una operación \textit  {max pooling} en una red convolucional}}{71}{figure.caption.23}\protected@file@percent }
\newlabel{fig:pooling}{{16}{71}{Ejemplo de una operación \textit {max pooling} en una red convolucional}{figure.caption.23}{}}
\newlabel{fig:pooling@cref}{{[figure][16][]16}{[1][70][]71}{}{}{}}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{ResNets}
\abx@aux@segm{0}{0}{ResNets}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4}Capa \textit  {Batch Normalization}}{72}{subsubsection.7.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.5}Capa totalmente conectada}{72}{subsubsection.7.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}\textit  {Residual Networks}}{72}{subsection.7.3}\protected@file@percent }
\newlabel{sec:resnets}{{7.3}{72}{\textit {Residual Networks}}{subsection.7.3}{}}
\newlabel{sec:resnets@cref}{{[subsection][3][7]7.3}{[1][72][]72}{}{}{}}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Comparación entre una red neuronal tradicional y una red residual}}{73}{figure.caption.24}\protected@file@percent }
\newlabel{fig:resblock}{{17}{73}{Comparación entre una red neuronal tradicional y una red residual}{figure.caption.24}{}}
\newlabel{fig:resblock@cref}{{[figure][17][]17}{[1][73][]73}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Bloques residuales}{73}{subsubsection.7.3.1}\protected@file@percent }
\abx@aux@cite{0}{bottleorig}
\abx@aux@segm{0}{0}{bottleorig}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Bloques residuales utilizados en \textit  {Residual Networks}}}{74}{figure.caption.25}\protected@file@percent }
\newlabel{fig:resblock1x1}{{18}{74}{Bloques residuales utilizados en \textit {Residual Networks}}{figure.caption.25}{}}
\newlabel{fig:resblock1x1@cref}{{[figure][18][]18}{[1][73][]74}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Convoluciones 1x1}{74}{subsubsection.7.3.2}\protected@file@percent }
\abx@aux@cite{0}{momentumorig}
\abx@aux@segm{0}{0}{momentumorig}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{Nesterov}
\abx@aux@segm{0}{0}{Nesterov}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Optimizadores basados en gradiente descendente}{75}{subsection.7.4}\protected@file@percent }
\newlabel{sec:gd}{{7.4}{75}{Optimizadores basados en gradiente descendente}{subsection.7.4}{}}
\newlabel{sec:gd@cref}{{[subsection][4][7]7.4}{[1][75][]75}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}NAG}{75}{subsubsection.7.4.1}\protected@file@percent }
\abx@aux@cite{0}{rmsprop}
\abx@aux@segm{0}{0}{rmsprop}
\abx@aux@cite{0}{rmsprop}
\abx@aux@segm{0}{0}{rmsprop}
\abx@aux@cite{0}{rmsprop}
\abx@aux@segm{0}{0}{rmsprop}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Comparación entre el algoritmo de gradiente descendente estocástico original y usando el momento}}{76}{figure.caption.26}\protected@file@percent }
\newlabel{fig:momentum}{{19}{76}{Comparación entre el algoritmo de gradiente descendente estocástico original y usando el momento}{figure.caption.26}{}}
\newlabel{fig:momentum@cref}{{[figure][19][]19}{[1][75][]76}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}RMSProp}{76}{subsubsection.7.4.2}\protected@file@percent }
\abx@aux@cite{0}{adagrad}
\abx@aux@segm{0}{0}{adagrad}
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{Adam}
\abx@aux@segm{0}{0}{Adam}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Comparación del cálculo del tamaño del paso entre los métodos del momento original y el momento de Nesterov}}{77}{figure.caption.27}\protected@file@percent }
\newlabel{fig:NAG}{{20}{77}{Comparación del cálculo del tamaño del paso entre los métodos del momento original y el momento de Nesterov}{figure.caption.27}{}}
\newlabel{fig:NAG@cref}{{[figure][20][]20}{[1][76][]77}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.3}Adam}{77}{subsubsection.7.4.3}\protected@file@percent }
\abx@aux@cite{0}{divedeeplearning}
\abx@aux@segm{0}{0}{divedeeplearning}
\abx@aux@cite{0}{GoodFellowBook}
\abx@aux@segm{0}{0}{GoodFellowBook}
\abx@aux@cite{0}{AdamW}
\abx@aux@segm{0}{0}{AdamW}
\abx@aux@cite{0}{L-BFGS-B}
\abx@aux@segm{0}{0}{L-BFGS-B}
\abx@aux@cite{0}{Numerical_optimization}
\abx@aux@segm{0}{0}{Numerical_optimization}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.4}AdamW}{78}{subsubsection.7.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.5}L-BFGS-B}{78}{subsubsection.7.4.5}\protected@file@percent }
\newlabel{sec:l-bfgs}{{7.4.5}{78}{L-BFGS-B}{subsubsection.7.4.5}{}}
\newlabel{sec:l-bfgs@cref}{{[subsubsection][5][7,4]7.4.5}{[1][78][]78}{}{}{}}
\abx@aux@cite{0}{BFGS}
\abx@aux@segm{0}{0}{BFGS}
\abx@aux@cite{0}{L-BFGS}
\abx@aux@segm{0}{0}{L-BFGS}
\abx@aux@cite{0}{stanford_231}
\abx@aux@segm{0}{0}{stanford_231}
\abx@aux@cite{0}{Numerical_optimization}
\abx@aux@segm{0}{0}{Numerical_optimization}
\abx@aux@cite{0}{mhhandbook}
\abx@aux@segm{0}{0}{mhhandbook}
\abx@aux@cite{0}{mhhandbook}
\abx@aux@segm{0}{0}{mhhandbook}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Metaheurísticas}{79}{subsection.7.5}\protected@file@percent }
\newlabel{sec:mh}{{7.5}{79}{Metaheurísticas}{subsection.7.5}{}}
\newlabel{sec:mh@cref}{{[subsection][5][7]7.5}{[1][79][]79}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Representación y cruce de cromosomas en algoritmos genéticos}}{80}{figure.caption.28}\protected@file@percent }
\newlabel{fig:cruce_mh}{{21}{80}{Representación y cruce de cromosomas en algoritmos genéticos}{figure.caption.28}{}}
\newlabel{fig:cruce_mh@cref}{{[figure][21][]21}{[1][80][]80}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Metaheurísticas basadas en poblaciones}{80}{subsubsection.7.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Etapas de un algoritmo genético}}{81}{figure.caption.29}\protected@file@percent }
\newlabel{fig:gen_alg}{{22}{81}{Etapas de un algoritmo genético}{figure.caption.29}{}}
\newlabel{fig:gen_alg@cref}{{[figure][22][]22}{[1][81][]81}{}{}{}}
\abx@aux@cite{0}{diffev}
\abx@aux@segm{0}{0}{diffev}
\abx@aux@cite{0}{diffevbook}
\abx@aux@segm{0}{0}{diffevbook}
\abx@aux@cite{0}{shade}
\abx@aux@segm{0}{0}{shade}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}\textit  {Differential Evolution}}{82}{subsubsection.7.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.3}SHADE}{82}{subsubsection.7.5.3}\protected@file@percent }
\abx@aux@cite{0}{shade}
\abx@aux@segm{0}{0}{shade}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Esquema general de DE}}{83}{algorithm.4}\protected@file@percent }
\newlabel{alg:de}{{4}{83}{Esquema general de DE}{algorithm.4}{}}
\newlabel{alg:de@cref}{{[algorithm][4][]4}{[1][82][]83}{}{}{}}
\abx@aux@cite{0}{mhhandbook}
\abx@aux@segm{0}{0}{mhhandbook}
\abx@aux@cite{0}{nofreelunch}
\abx@aux@segm{0}{0}{nofreelunch}
\abx@aux@cite{0}{shadeils}
\abx@aux@segm{0}{0}{shadeils}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Algoritmo SHADE}}{84}{algorithm.5}\protected@file@percent }
\newlabel{alg:shade}{{5}{84}{Algoritmo SHADE}{algorithm.5}{}}
\newlabel{alg:shade@cref}{{[algorithm][5][]5}{[1][83][]84}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.4}Algoritmos meméticos}{84}{subsubsection.7.5.4}\protected@file@percent }
\abx@aux@cite{0}{shadeils}
\abx@aux@segm{0}{0}{shadeils}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.5}SHADE-ILS}{85}{subsubsection.7.5.5}\protected@file@percent }
\newlabel{sec:shade-ils}{{7.5.5}{85}{SHADE-ILS}{subsubsection.7.5.5}{}}
\newlabel{sec:shade-ils@cref}{{[subsubsection][5][7,5]7.5.5}{[1][84][]85}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Algoritmo SHADE-ILS}}{86}{algorithm.6}\protected@file@percent }
\newlabel{alg:shade-ils}{{6}{86}{Algoritmo SHADE-ILS}{algorithm.6}{}}
\newlabel{alg:shade-ils@cref}{{[algorithm][6][]6}{[1][85][]86}{}{}{}}
\abx@aux@cite{0}{S-Wtest}
\abx@aux@segm{0}{0}{S-Wtest}
\abx@aux@cite{0}{Wilcoxon}
\abx@aux@segm{0}{0}{Wilcoxon}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Tests estadísticos}{87}{subsection.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.6.1}Test de Shapiro-Wilk}{87}{subsubsection.7.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.6.2}Test de los rangos con signo de Wilcoxon}{88}{subsubsection.7.6.2}\protected@file@percent }
\newlabel{sec:tests}{{7.6.2}{88}{Test de los rangos con signo de Wilcoxon}{subsubsection.7.6.2}{}}
\newlabel{sec:tests@cref}{{[subsubsection][2][7,6]7.6.2}{[1][87][]88}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Estado del arte}{89}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Gradiente descendente y optimizadores}{89}{subsection.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Número de documentos indexados anualmente en la base de datos Scopus relacionados con el entrenamiento de modelos de aprendizaje profundo mediante diferentes enfoques}}{90}{figure.caption.30}\protected@file@percent }
\newlabel{fig:resEdA}{{23}{90}{Número de documentos indexados anualmente en la base de datos Scopus relacionados con el entrenamiento de modelos de aprendizaje profundo mediante diferentes enfoques}{figure.caption.30}{}}
\newlabel{fig:resEdA@cref}{{[figure][23][]23}{[1][89][]90}{}{}{}}
\abx@aux@cite{0}{Kyrillidis2020}
\abx@aux@segm{0}{0}{Kyrillidis2020}
\abx@aux@cite{0}{yellowfin}
\abx@aux@segm{0}{0}{yellowfin}
\abx@aux@cite{0}{162}
\abx@aux@segm{0}{0}{162}
\abx@aux@cite{0}{beesalgo}
\abx@aux@segm{0}{0}{beesalgo}
\abx@aux@cite{0}{155}
\abx@aux@segm{0}{0}{155}
\abx@aux@cite{0}{163}
\abx@aux@segm{0}{0}{163}
\abx@aux@cite{0}{pso}
\abx@aux@segm{0}{0}{pso}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Metaheurísticas en el entrenamiento de modelos}{92}{subsection.8.2}\protected@file@percent }
\abx@aux@cite{0}{174}
\abx@aux@segm{0}{0}{174}
\abx@aux@cite{0}{176}
\abx@aux@segm{0}{0}{176}
\abx@aux@cite{0}{siman}
\abx@aux@segm{0}{0}{siman}
\abx@aux@cite{0}{Yao1999}
\abx@aux@segm{0}{0}{Yao1999}
\abx@aux@cite{0}{Whitley1990}
\abx@aux@segm{0}{0}{Whitley1990}
\abx@aux@cite{0}{Stanley2019}
\abx@aux@segm{0}{0}{Stanley2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Neuroevolución}{93}{subsection.8.3}\protected@file@percent }
\abx@aux@cite{0}{Stanley2002}
\abx@aux@segm{0}{0}{Stanley2002}
\abx@aux@cite{0}{David2014}
\abx@aux@segm{0}{0}{David2014}
\abx@aux@cite{0}{Such2017}
\abx@aux@segm{0}{0}{Such2017}
\abx@aux@cite{0}{Miikkulainen2019}
\abx@aux@segm{0}{0}{Miikkulainen2019}
\abx@aux@cite{0}{Pavlidis2005}
\abx@aux@segm{0}{0}{Pavlidis2005}
\abx@aux@cite{0}{Stanley2019}
\abx@aux@segm{0}{0}{Stanley2019}
\abx@aux@cite{0}{Slowik2008}
\abx@aux@segm{0}{0}{Slowik2008}
\abx@aux@cite{0}{Kaveh2023}
\abx@aux@segm{0}{0}{Kaveh2023}
\abx@aux@cite{0}{Hutter2019}
\abx@aux@segm{0}{0}{Hutter2019}
\abx@aux@cite{0}{Hutter2019}
\abx@aux@segm{0}{0}{Hutter2019}
\abx@aux@cite{0}{Kaveh2023}
\abx@aux@segm{0}{0}{Kaveh2023}
\abx@aux@cite{0}{Shahriari2016}
\abx@aux@segm{0}{0}{Shahriari2016}
\abx@aux@cite{0}{Alba2006}
\abx@aux@segm{0}{0}{Alba2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Aprendizaje Automático Automatizado}{95}{subsection.8.4}\protected@file@percent }
\abx@aux@cite{0}{Miikkulainen2019}
\abx@aux@segm{0}{0}{Miikkulainen2019}
\abx@aux@cite{0}{Li2018}
\abx@aux@segm{0}{0}{Li2018}
\abx@aux@cite{0}{Hutter2019}
\abx@aux@segm{0}{0}{Hutter2019}
\abx@aux@cite{0}{Elsken2019}
\abx@aux@segm{0}{0}{Elsken2019}
\abx@aux@cite{0}{Elsken2019}
\abx@aux@segm{0}{0}{Elsken2019}
\abx@aux@cite{0}{Zoph2017}
\abx@aux@segm{0}{0}{Zoph2017}
\abx@aux@cite{0}{Zoph2017}
\abx@aux@segm{0}{0}{Zoph2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Búsqueda de Arquitectura Neuronal}{96}{subsection.8.5}\protected@file@percent }
\abx@aux@cite{0}{Xie2017}
\abx@aux@segm{0}{0}{Xie2017}
\abx@aux@cite{0}{Lu2018}
\abx@aux@segm{0}{0}{Lu2018}
\abx@aux@cite{0}{Stanley2019}
\abx@aux@segm{0}{0}{Stanley2019}
\abx@aux@cite{0}{Stanley2002}
\abx@aux@segm{0}{0}{Stanley2002}
\abx@aux@cite{0}{Liu2018}
\abx@aux@segm{0}{0}{Liu2018}
\abx@aux@cite{0}{Pham2018}
\abx@aux@segm{0}{0}{Pham2018}
\abx@aux@cite{0}{Baker2018}
\abx@aux@segm{0}{0}{Baker2018}
\abx@aux@cite{0}{Miikkulainen2019}
\abx@aux@segm{0}{0}{Miikkulainen2019}
\abx@aux@cite{0}{Liu2018}
\abx@aux@segm{0}{0}{Liu2018}
\abx@aux@cite{0}{Zoph2018}
\abx@aux@segm{0}{0}{Zoph2018}
\abx@aux@cite{0}{Lu2018}
\abx@aux@segm{0}{0}{Lu2018}
\abx@aux@cite{0}{Lu2018}
\abx@aux@segm{0}{0}{Lu2018}
\abx@aux@cite{0}{Real2019}
\abx@aux@segm{0}{0}{Real2019}
\abx@aux@cite{0}{Gao2020}
\abx@aux@segm{0}{0}{Gao2020}
\abx@aux@cite{0}{Kaveh2023}
\abx@aux@segm{0}{0}{Kaveh2023}
\abx@aux@cite{0}{shadeils}
\abx@aux@segm{0}{0}{shadeils}
\abx@aux@cite{0}{shade}
\abx@aux@segm{0}{0}{shade}
\abx@aux@cite{0}{shadeils}
\abx@aux@segm{0}{0}{shadeils}
\@writefile{toc}{\contentsline {section}{\numberline {9}Métodos propuestos}{99}{section.9}\protected@file@percent }
\newlabel{sec:propuestas}{{9}{99}{Métodos propuestos}{section.9}{}}
\newlabel{sec:propuestas@cref}{{[section][9][]9}{[1][99][]99}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}SHADE-GD}{100}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Inicialización\\}{100}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Bucle principal de optimización\\}{100}{section*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Diagramas de flujo de los algoritmos SHADE-GD y SHADE-ILS-GD}}{101}{figure.caption.31}\protected@file@percent }
\newlabel{fig:flowchart}{{24}{101}{Diagramas de flujo de los algoritmos SHADE-GD y SHADE-ILS-GD}{figure.caption.31}{}}
\newlabel{fig:flowchart@cref}{{[figure][24][]24}{[1][100][]101}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Algoritmo SHADE-GD}}{102}{algorithm.7}\protected@file@percent }
\newlabel{alg:shade-gd}{{7}{102}{Algoritmo SHADE-GD}{algorithm.7}{}}
\newlabel{alg:shade-gd@cref}{{[algorithm][7][]7}{[1][100][]102}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{3. Aplicación periódica de GD\\}{103}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{4. Criterio de reinicio de población\\}{103}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{5. Finalización\\}{104}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusión\\}{104}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}SHADE-ILS-GD}{104}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Inicialización\\}{104}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Bucle principal de optimización}{104}{section*.39}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces Algoritmo SHADE-ILS-GD}}{105}{algorithm.8}\protected@file@percent }
\newlabel{alg:shade-ils-gd}{{8}{105}{Algoritmo SHADE-ILS-GD}{algorithm.8}{}}
\newlabel{alg:shade-ils-gd@cref}{{[algorithm][8][]8}{[1][104][]105}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{3. Aplicación periódica de GD\\}{106}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{4. Actualización de la mejor solución global\\}{106}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{5. Criterio de reinicio de población\\}{106}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{6. Finalización\\}{106}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusión\\}{107}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Experimentación y resultados}{108}{section.10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Descripción de los experimentos realizados, optimizadores evaluados, conjuntos de datos utilizados y modelos empleados en el estudio}}{108}{table.caption.45}\protected@file@percent }
\newlabel{tab:res_exp}{{2}{108}{Descripción de los experimentos realizados, optimizadores evaluados, conjuntos de datos utilizados y modelos empleados en el estudio}{table.caption.45}{}}
\newlabel{tab:res_exp@cref}{{[table][2][]2}{[1][108][]108}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Entorno de ejecución y detalles de implementación}{108}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.1}Gradiente descendente}{109}{subsubsection.10.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.2}Metaheurísticas}{110}{subsubsection.10.1.2}\protected@file@percent }
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.3}Entrenamiento}{112}{subsubsection.10.1.3}\protected@file@percent }
\abx@aux@cite{0}{MHtrainingClase}
\abx@aux@segm{0}{0}{MHtrainingClase}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Hiperparámetros utilizados en el entrenamiento}}{113}{table.caption.46}\protected@file@percent }
\newlabel{tab:params}{{3}{113}{Hiperparámetros utilizados en el entrenamiento}{table.caption.46}{}}
\newlabel{tab:params@cref}{{[table][3][]3}{[1][113][]113}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.4}Métricas de evaluación utilizadas}{114}{subsubsection.10.1.4}\protected@file@percent }
\newlabel{subsubsec:metricas}{{10.1.4}{114}{Métricas de evaluación utilizadas}{subsubsection.10.1.4}{}}
\newlabel{subsubsec:metricas@cref}{{[subsubsection][4][10,1]10.1.4}{[1][113][]114}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Regresión.}{114}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Clasificación con clases balanceadas.}{114}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Clasificación con clases desbalanceadas.}{114}{section*.49}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Características de los conjuntos de datos tabulares utilizados en la experimentación}}{115}{table.caption.50}\protected@file@percent }
\newlabel{tab:dat_tab}{{4}{115}{Características de los conjuntos de datos tabulares utilizados en la experimentación}{table.caption.50}{}}
\newlabel{tab:dat_tab@cref}{{[table][4][]4}{[1][115][]115}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Conjuntos de datos}{115}{subsection.10.2}\protected@file@percent }
\newlabel{sec:conjuntos_de_datos}{{10.2}{115}{Conjuntos de datos}{subsection.10.2}{}}
\newlabel{sec:conjuntos_de_datos@cref}{{[subsection][2][10]10.2}{[1][115][]115}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}Tabulares}{115}{subsubsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.2}Imágenes}{116}{subsubsection.10.2.2}\protected@file@percent }
\newlabel{fig:mnist}{{25a}{117}{Subfigure 25a}{subfigure.25.1}{}}
\newlabel{sub@fig:mnist}{{(a)}{a}{Subfigure 25a\relax }{subfigure.25.1}{}}
\newlabel{fig:mnist@cref}{{[subfigure][1][25]25a}{[1][116][]117}{}{}{}}
\newlabel{fig:fmnist}{{25b}{117}{Subfigure 25b}{subfigure.25.2}{}}
\newlabel{sub@fig:fmnist}{{(b)}{b}{Subfigure 25b\relax }{subfigure.25.2}{}}
\newlabel{fig:fmnist@cref}{{[subfigure][2][25]25b}{[1][116][]117}{}{}{}}
\newlabel{fig:cifar10}{{25c}{117}{Subfigure 25c}{subfigure.25.3}{}}
\newlabel{sub@fig:cifar10}{{(c)}{c}{Subfigure 25c\relax }{subfigure.25.3}{}}
\newlabel{fig:cifar10@cref}{{[subfigure][3][25]25c}{[1][116][]117}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Ejemplos de imágenes de los conjuntos de datos utilizados en la experimentación para clasificación de imágenes}}{117}{figure.caption.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Modelos}{118}{subsection.10.3}\protected@file@percent }
\newlabel{sec:modelos}{{10.3}{118}{Modelos}{subsection.10.3}{}}
\newlabel{sec:modelos@cref}{{[subsection][3][10]10.3}{[1][118][]118}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Características de los modelos de Perceptrón Multicapa utilizados en la experimentación}}{119}{table.caption.52}\protected@file@percent }
\newlabel{tab:MLPmod}{{5}{119}{Características de los modelos de Perceptrón Multicapa utilizados en la experimentación}{table.caption.52}{}}
\newlabel{tab:MLPmod@cref}{{[table][5][]5}{[1][118][]119}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Experimentos}{119}{subsection.10.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Arquitectura del modelo LeNet5 utilizado en la experimentación para clasificación de imágenes de 28×28 píxeles con un solo canal de entrada}}{120}{table.caption.53}\protected@file@percent }
\newlabel{table:lenet5}{{6}{120}{Arquitectura del modelo LeNet5 utilizado en la experimentación para clasificación de imágenes de 28×28 píxeles con un solo canal de entrada}{table.caption.53}{}}
\newlabel{table:lenet5@cref}{{[table][6][]6}{[1][119][]120}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Arquitectura del modelo ResNet57 utilizado en la experimentación para clasificación de imágenes de 28×28 píxeles con un solo canal de entrada}}{121}{table.caption.54}\protected@file@percent }
\newlabel{table:resnet57}{{7}{121}{Arquitectura del modelo ResNet57 utilizado en la experimentación para clasificación de imágenes de 28×28 píxeles con un solo canal de entrada}{table.caption.54}{}}
\newlabel{table:resnet57@cref}{{[table][7][]7}{[1][119][]121}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.4.1}Experimento 1: Análisis de diferencias en el rendimiento de MLPs entrenados con MH según el tipo de tarea}{121}{subsubsection.10.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Arquitectura del modelo ResNet15 utilizado en la experimentación para clasificación de imágenes de 28x28 píxeles con un solo canal de entrada}}{122}{table.caption.55}\protected@file@percent }
\newlabel{table:resnet15}{{8}{122}{Arquitectura del modelo ResNet15 utilizado en la experimentación para clasificación de imágenes de 28x28 píxeles con un solo canal de entrada}{table.caption.55}{}}
\newlabel{table:resnet15@cref}{{[table][8][]8}{[1][119][]122}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Resultados del entrenamiento y evaluación de los modelos asociados al primer experimento}}{123}{table.caption.56}\protected@file@percent }
\newlabel{tab:exp1}{{9}{123}{Resultados del entrenamiento y evaluación de los modelos asociados al primer experimento}{table.caption.56}{}}
\newlabel{tab:exp1@cref}{{[table][9][]9}{[1][121][]123}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Resultado de los tests estadísticos llevados a cabo durante el primer experimento}}{124}{table.caption.57}\protected@file@percent }
\newlabel{tab:stats}{{10}{124}{Resultado de los tests estadísticos llevados a cabo durante el primer experimento}{table.caption.57}{}}
\newlabel{tab:stats@cref}{{[table][10][]10}{[1][124][]124}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.4.2}Experimento 2: Evaluación de los factores que más afectan a la pérdida de rendimiento en tareas de clasificación, tanto en MLPs como en ConvNets}{125}{subsubsection.10.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Resultados del entrenamiento para SHADE y SHADE-ILS en tareas de clasificación, considerando la complejidad del conjunto de datos, su tamaño, y el número de parámetros del modelo}}{128}{table.caption.58}\protected@file@percent }
\newlabel{tab:esc1}{{11}{128}{Resultados del entrenamiento para SHADE y SHADE-ILS en tareas de clasificación, considerando la complejidad del conjunto de datos, su tamaño, y el número de parámetros del modelo}{table.caption.58}{}}
\newlabel{tab:esc1@cref}{{[table][11][]11}{[1][127][]128}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Valores analíticos asignados a los conjuntos de datos para el segundo experimento}}{128}{table.caption.60}\protected@file@percent }
\newlabel{tab:expP1}{{13}{128}{Valores analíticos asignados a los conjuntos de datos para el segundo experimento}{table.caption.60}{}}
\newlabel{tab:expP1@cref}{{[table][13][]13}{[1][127][]128}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Resultados del entrenamiento para AdamW y RMSProp en tareas de clasificación, considerando la complejidad del conjunto de datos, su tamaño, y el número de parámetros del modelo}}{129}{table.caption.59}\protected@file@percent }
\newlabel{tab:esc2}{{12}{129}{Resultados del entrenamiento para AdamW y RMSProp en tareas de clasificación, considerando la complejidad del conjunto de datos, su tamaño, y el número de parámetros del modelo}{table.caption.59}{}}
\newlabel{tab:esc2@cref}{{[table][12][]12}{[1][127][]129}{}{}{}}
\newlabel{fig:pda_mh}{{26a}{130}{Subfigure 26a}{subfigure.26.1}{}}
\newlabel{sub@fig:pda_mh}{{(a)}{a}{Subfigure 26a\relax }{subfigure.26.1}{}}
\newlabel{fig:pda_mh@cref}{{[subfigure][1][26]26a}{[1][129][]130}{}{}{}}
\newlabel{fig:pda_gd}{{26b}{130}{Subfigure 26b}{subfigure.26.2}{}}
\newlabel{sub@fig:pda_gd}{{(b)}{b}{Subfigure 26b\relax }{subfigure.26.2}{}}
\newlabel{fig:pda_gd@cref}{{[subfigure][2][26]26b}{[1][129][]130}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Análisis de dependencias parciales del rendimiento relativo al clasificador aleatorio en función de la complejidad del conjunto de datos, el tamaño del conjunto de datos y el número de parámetros del modelo}}{130}{figure.caption.61}\protected@file@percent }
\newlabel{fig:pda}{{26}{130}{Análisis de dependencias parciales del rendimiento relativo al clasificador aleatorio en función de la complejidad del conjunto de datos, el tamaño del conjunto de datos y el número de parámetros del modelo}{figure.caption.61}{}}
\newlabel{fig:pda@cref}{{[figure][26][]26}{[1][129][]130}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.4.3}Experimento 3: Análisis de los tiempos de ejecución en el entrenamiento con MH, tanto en MLPs como en ConvNets}{131}{subsubsection.10.4.3}\protected@file@percent }
\newlabel{fig:tiempoinst}{{27a}{132}{Subfigure 27a}{subfigure.27.1}{}}
\newlabel{sub@fig:tiempoinst}{{(a)}{a}{Subfigure 27a\relax }{subfigure.27.1}{}}
\newlabel{fig:tiempoinst@cref}{{[subfigure][1][27]27a}{[1][131][]132}{}{}{}}
\newlabel{fig:tiempoparam}{{27b}{132}{Subfigure 27b}{subfigure.27.2}{}}
\newlabel{sub@fig:tiempoparam}{{(b)}{b}{Subfigure 27b\relax }{subfigure.27.2}{}}
\newlabel{fig:tiempoparam@cref}{{[subfigure][2][27]27b}{[1][131][]132}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Representación gráfica del tiempo de ejecución de los algoritmos SHADE-ILS y AdamW en función del número de parámetros del modelo}}{132}{figure.caption.63}\protected@file@percent }
\newlabel{fig:tiemposgraf}{{27}{132}{Representación gráfica del tiempo de ejecución de los algoritmos SHADE-ILS y AdamW en función del número de parámetros del modelo}{figure.caption.63}{}}
\newlabel{fig:tiemposgraf@cref}{{[figure][27][]27}{[1][131][]132}{}{}{}}
\newlabel{fig:tiempoinst_gd}{{28a}{133}{Subfigure 28a}{subfigure.28.1}{}}
\newlabel{sub@fig:tiempoinst_gd}{{(a)}{a}{Subfigure 28a\relax }{subfigure.28.1}{}}
\newlabel{fig:tiempoinst_gd@cref}{{[subfigure][1][28]28a}{[1][131][]133}{}{}{}}
\newlabel{fig:tiempoparam_gd}{{28b}{133}{Subfigure 28b}{subfigure.28.2}{}}
\newlabel{sub@fig:tiempoparam_gd}{{(b)}{b}{Subfigure 28b\relax }{subfigure.28.2}{}}
\newlabel{fig:tiempoparam_gd@cref}{{[subfigure][2][28]28b}{[1][131][]133}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Representación gráfica del tiempo de ejecución de AdamW en función del número de parámetros del modelo}}{133}{figure.caption.64}\protected@file@percent }
\newlabel{fig:tiemposgraf}{{28}{133}{Representación gráfica del tiempo de ejecución de AdamW en función del número de parámetros del modelo}{figure.caption.64}{}}
\newlabel{fig:tiemposgraf@cref}{{[figure][28][]28}{[1][131][]133}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Comparación de tiempos entre los algoritmos SHADE-ILS y AdamW}}{134}{table.caption.62}\protected@file@percent }
\newlabel{tab:tiempos}{{14}{134}{Comparación de tiempos entre los algoritmos SHADE-ILS y AdamW}{table.caption.62}{}}
\newlabel{tab:tiempos@cref}{{[table][14][]14}{[1][131][]134}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.4.4}Experimento 4: Análisis comparativo de las propuestas propias}{136}{subsubsection.10.4.4}\protected@file@percent }
\newlabel{sec:res_propias}{{10.4.4}{136}{Experimento 4: Análisis comparativo de las propuestas propias}{subsubsection.10.4.4}{}}
\newlabel{sec:res_propias@cref}{{[subsubsection][4][10,4]10.4.4}{[1][136][]136}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{SHADE y SHADE-GD\\}{136}{section*.66}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Comparación del desempeño de SHADE y SHADE-GD en el entrenamiento de modelos de aprendizaje profundo sobre conjuntos de datos tabulares e imágenes}}{137}{table.caption.65}\protected@file@percent }
\newlabel{tab:shadevsshadegd}{{15}{137}{Comparación del desempeño de SHADE y SHADE-GD en el entrenamiento de modelos de aprendizaje profundo sobre conjuntos de datos tabulares e imágenes}{table.caption.65}{}}
\newlabel{tab:shadevsshadegd@cref}{{[table][15][]15}{[1][136][]137}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{SHADE-ILS y SHADE-ILS-GD\\}{138}{section*.68}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Comparación del desempeño de SHADE-ILS y SHADE-ILS-GD en el entrenamiento de modelos de aprendizaje profundo sobre conjuntos de datos tabulares e imágenes}}{139}{table.caption.67}\protected@file@percent }
\newlabel{tab:ilsvsilsgd}{{16}{139}{Comparación del desempeño de SHADE-ILS y SHADE-ILS-GD en el entrenamiento de modelos de aprendizaje profundo sobre conjuntos de datos tabulares e imágenes}{table.caption.67}{}}
\newlabel{tab:ilsvsilsgd@cref}{{[table][16][]16}{[1][138][]139}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{SHADE-GD y SHADE-ILS-GD\\}{140}{section*.70}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Comparación del desempeño de SHADE-GD y SHADE-ILS-GD en el entrenamiento de modelos de aprendizaje profundo sobre conjuntos de datos tabulares e imágenes}}{141}{table.caption.69}\protected@file@percent }
\newlabel{tab:shadegdvsilsgd}{{17}{141}{Comparación del desempeño de SHADE-GD y SHADE-ILS-GD en el entrenamiento de modelos de aprendizaje profundo sobre conjuntos de datos tabulares e imágenes}{table.caption.69}{}}
\newlabel{tab:shadegdvsilsgd@cref}{{[table][17][]17}{[1][140][]141}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Conclusiones y trabajos futuros}{143}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Bibliografía}{146}{Item.57}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{0296C19FBA1E658D47B04ACC79B3C924}
\abx@aux@defaultrefcontext{0}{Ahmadi_2011_NP_Convex}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Alba2006}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Mostafa2012}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{axler2024linear}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{176}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Baker2018}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{162}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{AutomaticDiff}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{bishop2023learning}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Zoph2017}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ReLuat0}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{patternrecog}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lecunnDeepForAI}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{pso}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{convexSubgrad}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ConvexOp}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{L-BFGS-B}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{CauchyGD}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Curry1944GDNoLin}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{NIPS2014_17e23e50}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Problem3_accel}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{David2014}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{adagrad}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{de2015global}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Elsken2019}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{BFGS}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{stanford_231}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{fehrman2020convergence}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Gao2020}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{stabilityProblem2}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{GoodFellowBook}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mhhandbook}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{heinic}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ResNets}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rmsprop}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Hutter2019}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{VanishExplode}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{batchnorm}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{beesalgo}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Adam}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{siman}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{163}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Kaveh2023}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{NIPS2012_c399862d}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Kyrillidis2020}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{stochastic}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lecun2015deep}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{bottleorig}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{EffBackProp}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{AdamW}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{LiVisualizing}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Li2018}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{L-BFGS}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Liu2018}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Lu2018}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{MHtrainingClase}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mertikopoulos2020almost}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Miikkulainen2019}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mitchell1997machine}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{NPHardProblem}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{shadeils}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Mculloch43}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{pml1Book}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Nesterov}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alternativabackprop1}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alternativabacknumerical}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Numerical_optimization}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Pavlidis2005}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Pham2018}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{155}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{prince2023understanding}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{diffevbook}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{momentumorig}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Real2019}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{174}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rumelbackprop}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{perceptron}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{optimal_gd}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{2016modernapp}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Slowik2008}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Shahriari2016}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{SCHMIDHUBER201585}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Sejnowski18}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Stanley2002}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{IngSoft}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{diffev}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Stanley2019}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Such2017}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{S-Wtest}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{MH_desing_imp}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{shade}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{tibshirani2013convex}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Wilcoxon}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{nofreelunch}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Whitley1990}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Yao1999}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Xie2017}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{figRelu1}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{divedeeplearning}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{yellowfin}{anyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Zoph2018}{anyt/global//global/global/global}
\gdef \@abspage@last{169}
