\section{Estado del Arte}
Mejores modelos de aprendizaje profundo y de redes convolucionales a día de hoy. Mencionar su arquitectura, resultados diferenciales, logros. Mencionar otras familias de modelos y su comparación con convnets. Tamaño y requerimientos computacionales de los modelos actuales, nº de parámetros, de capas, innovaciones en capas/arquitecturas... poner ejemplos concretos.


\subsection{Gradiente descendente}
Paper de estado del arte en optimizadores de primer orden. Ver alcance de los métodos de segundo orden, contribuciones teóricas y grandes limitaciones.

\subsection{Metaheurísticas en aprendizaje automatico}

Mencionar un poco por encima su uso para selección de hiperparámetros y elección de arquitecturas. Desarrollar sobre su uso en el entrenamiento para la modificación de pesos: sobreentrenan, no mejoran en rendimiento pero pueden ser una alternativa con vistas de futuro. Ejemplos de papers recientes

\subsection{Metodos de entrenamiento alternativos}

Explorar alternativas no basadas en metaheuristicas ni GD, como descenso de coordenada (creo que no se usa mucho actualmente). 