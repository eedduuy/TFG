\section{Conclusiones y trabajos futuros}

En la parte informática de este TFG hemos investigado, desde una perspectiva eminentemente empírica, el uso de técnicas MH como alternativa al GD para el entrenamiento de modelos de aprendizaje profundo. Resulta crucial comprender cómo los enfoques clásicos se comparan con técnicas como las MH, que pueden ofrecer ventajas en términos de exploración del espacio de soluciones. Este estudio es relevante porque permite no solo evaluar el rendimiento de estos métodos en diferentes contextos, sino también aportar una visión sobre cómo pueden integrarse de manera más eficiente en la práctica de la inteligencia artificial. El código asociado al proyecto se puede encontrar en \url{https://github.com/eedduu/TFG}.

Al principio nos fijamos como objetivo principal ``evaluar y analizar la eficacia de las técnicas MH para el entrenamiento de redes neuronales profundas en comparación con el algoritmo de GD, para tener una mejor comprensión de cuáles son las diferencias principales en el rendimiento de estas dos estrategias y cuáles son las causas de las mismas''. Creemos que este objetivo se ha cumplido de manera satisfactoria, basándonos en el desglose de los objetivos parciales:
\begin{itemize}

\item En relación con el estudio de la literatura existente, se ha constatado el dominio absoluto de los métodos basados en GD en el ámbito del aprendizaje profundo, tanto en términos de rendimiento como de adopción. El análisis bibliométrico refleja esta hegemonía, con una diferencia de proporción de 7 a 1 en publicaciones frente a las MH. Sin embargo, también se ha evidenciado un creciente interés por las MH y enfoques híbridos, especialmente en áreas como la neuroevolución, AutoML y NAS, donde las limitaciones del GD abren la puerta a técnicas alternativas más flexibles. Estas estrategias, aunque aún menos eficientes en términos computacionales y de generalización, muestran potencial en tareas específicas y complejas. Esta revisión ha permitido contextualizar los objetivos experimentales y ha confirmado que la hibridación entre GD y MH no solo es prometedora, sino que se alinea con las tendencias más recientes en la literatura científica.

\item Nos planteamos si el tipo de tarea (clasificación o regresión) afecta al rendimiento de las MH. Para ello utilizamos modelos de la familia MLP entrenados con MH, donde medimos su rendimiento de manera relativa en comparación al mismo modelo entrenado con un optimizador basado en GD. Al aplicar el test de los rangos con signo de Wilcoxon obtuvimos un p-valor de 0.023, confirmando que\textbf{ existe una diferencia estadística significativa entre el rendimiento, relativo al GD, de las tareas de regresión y de clasificación.} Aun así, esta detección parece bastante sensible a los optimizadores incluidos, por lo que este resultado debe tomarse con cautela.

\item Sabemos que cuando aumenta la dificultad de la tarea el rendimiento de los modelos decae, especialmente en los entrenados con MH. Averiguamos qué factores concretos influían más en ésto, seleccionando tres: la complejidad del conjunto de datos, el número de instancias y el número de parámetros del modelo. \textbf{A través de un análisis de dependencias parciales concluimos que el aumento del número de ejemplos en una tarea es la variable que más hace decrecer el rendimiento de los modelos entrenados con MH, mientras que en el caso de los optimizadores basados en GD la complejidad del conjunto de datos es el factor más influyente}. Se han encontrado fuertes evidencias que respaldan tanto las observaciones empíricas como los conocimientos teóricos.

\item Con el objetivo de abordar la diferencia de tiempos en la ejecución de las dos estrategias, realizamos un análisis pormenorizado de los tiempos de ejecución de los algoritmos MH. Aunque necesitan de muchas más épocas de ejecución para alcanzar rendimientos aceptables, haciendo que se alargue más el entrenamiento, \textbf{comprobamos que el tiempo de ejecución por época es menor en el caso de las estrategias MH}. Además con este estudio hemos confirmado que \textbf{el tamaño del conjunto de datos afecta más al tiempo de ejecución que el número de parámetros del modelo a entrenar}, tanto en MH como en GD. Para nuestros experimentos, esta diferencia se daba en una proporción de entre 7 y 10 veces más.

\item \textbf{Hemos propuesto dos algoritmos originales, SHADE-GD y SHADE-ILS-GD}, y los hemos comparado a sus respectivas versiones originales. \textbf{De un total de 25 tareas afrontadas, SHADE-GD ha destacado en 17 de ellas, mientras que SHADE solo mejora el rendimiento a nuestra propuesta en 4 de ellas}. Por otro lado, \textbf{aunque SHADE-ILS-GD mejora el rendimiento respecto a su versión original en algunas tareas concretas de baja dificultad, llegando a obtener un 14\% más de \textit{accuracy} en algún caso, no se posiciona como una mejora consistente}. En modelos más profundos es menos estable y obtiene peores resultados. No obstante, cabe destacar que una de nuestras propuestas mejora a la versión original. \textbf{Cuando hemos comparado las dos propuestas entre sí, hemos obtenido un resultado parejo, en el que no hay un ganador claro, aunque de manera general se observa que SHADE-GD generaliza mejor}.

\end{itemize}

Ha sido necesario asentar y poner en práctica los conocimientos adquiridos a lo largo de todo el grado, como la capacidad de resolver problemas, así como el análisis y planificación de los mismos. Muchos de los contenidos de las asignaturas de Aprendizaje Automático, Visión por Computador y Metaheurísticas han tenido que ser revisados minuciosamente. Al comienzo del proyecto, ha sido necesario entender de manera profunda cómo funciona el proceso de entrenamiento del algoritmo de aprendizaje del GD y los optimizadores basados en éste. También se ha requerido una investigación para analizar cómo se relacionan las técnicas MH con problemas de optimización continua a gran escala, como es el entrenamiento de modelos de aprendizaje profundo. Además, fue necesario investigar sobre la literatura reciente para tomar decisiones en cuanto a la experimentación y el entorno de trabajo.

Destacamos que, a parte de corroborar de manera empírica algunos aspectos ya conocidos en la literatura en lo relativo a la superioridad de los optimizadores basados en GD sobre las MH, hemos podido obtener una conclusión que, hasta donde sabemos, es nueva en la literatura:

\begin{itemize}

\item \textbf{El rendimiento de los modelos entrenados con MH se ve más afectado por el tamaño del conjunto de datos que por la complejidad del mismo o por el número de parámetros del modelo}. En nuestros experimentos, las MH tienden a obtener peores resultados en conjuntos de datos más grandes, posiblemente debido a su limitada capacidad para extraer patrones complejos cuando el número de iteraciones se mantiene constante.
\end{itemize}

En resumen, los hallazgos obtenidos confirman una inclinación a favor de los optimizadores basados en GD frente a las MH para el entrenamiento de redes profundas, destacando su superior eficiencia y solidez. No obstante, este estudio proporciona una comprensión más detallada de las debilidades y posibilidades de las MH, y propone un marco analítico valioso para investigaciones futuras orientadas a optimizar su desempeño o identificar contextos específicos donde puedan resultar competitivas.

Después de analizar los resultados de este TFG, exponemos algunos posibles trabajos futuros:

\begin{enumerate}
	\item Un posible trabajo futuro es explorar estrategias híbridas entre MH y GD que consideren la estructura jerárquica de las redes neuronales profundas. Una idea interesante sería aplicar diferentes técnicas de optimización según el nivel de abstracción de las capas, por ejemplo, evaluando si las MH pueden ser más efectivas en las capas profundas, donde la optimización es más compleja, mientras que el GD podría aprovecharse en capas superficiales para ajustes más finos. Esto permitiría investigar si una asignación diferenciada de estrategias contribuye a mejorar la eficiencia y la convergencia del entrenamiento.
	
	\item Otro enfoque a explorar es el uso de MH no solo para entrenar redes neuronales, sino para generar automáticamente su arquitectura. Esto incluiría definir aspectos como el número de capas, la cantidad de neuronas por capa y otros hiperparámetros estructurales mediante un proceso de optimización. Comparar este enfoque con técnicas existentes, como NAS, permitiría evaluar hasta qué punto las MH pueden ser una alternativa viable y qué ventajas o desafíos presentan en términos de exploración del espacio de arquitecturas y costos computacionales.
\end{enumerate}


