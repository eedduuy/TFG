\section*{Resumen}
\addcontentsline{toc}{section}{Resumen}

En la parte Matemática del presente TFG se abordará el algoritmo de gradiente descendente desde una perspectiva teórica, analizando su funcionamiento, variantes, y problemas asociados a la convergencia. En primer lugar, se exploran las diferentes versiones del algoritmo, así como los elementos clave de su funcionamiento, prestando especial atención a su implementación en redes neuronales mediante el proceso de \textit{backpropagation}. A continuación, se profundiza en el concepto de subgradiente y su aplicación en el contexto de funciones no diferenciables, que amplían la utilidad del gradiente descendente en problemas complejos de optimización.

El enfoque principal de la investigación se centra en la convergencia de este algoritmo, tanto en su versión clásica (\textit{Batch Gradient Descent}) como en su versión estocástica (\textit{Stochastic Gradient Descent}). Para la primera, se demuestra que bajo condiciones específicas de convexidad y suavidad, el algoritmo converge al mínimo global de la función de coste. En el caso estocástico, se emplean herramientas avanzadas de teoría de probabilidad, en particular el teorema de Robbins-Siegmund y el concepto de martingalas, para caracterizar las condiciones necesarias para la convergencia del \textit{Stochastic Gradient Descent}, con especial atención a los efectos de la aleatoriedad inherente al gradiente en cada iteración.

Los resultados obtenidos proporcionan una comprensión más profunda de los aspectos matemáticos subyacentes al comportamiento del gradiente descendente, y ofrecen implicaciones importantes para la implementación de algoritmos de optimización en el ámbito del aprendizaje automático. En particular, se destacan las condiciones necesarias para asegurar una convergencia efectiva y estable en entornos de alta dimensionalidad y bajo ruido estocástico.

\newpage 

